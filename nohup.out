Traceback (most recent call last):
  File "run_summarization.py", line 27, in <module>
    import datasets
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/datasets/__init__.py", line 33, in <module>
    from .arrow_dataset import Dataset, concatenate_datasets
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 45, in <module>
    from .arrow_reader import ArrowReader
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/datasets/arrow_reader.py", line 28, in <module>
    import pyarrow.parquet as pq
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/pyarrow/parquet.py", line 40, in <module>
    from pyarrow.fs import (LocalFileSystem, FileSystem,
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/pyarrow/fs.py", line 52, in <module>
    initialize_s3()
KeyboardInterrupt
Traceback (most recent call last):
  File "run_summarization.py", line 27, in <module>
    import datasets
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/datasets/__init__.py", line 33, in <module>
    from .arrow_dataset import Dataset, concatenate_datasets
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 34, in <module>
    import fsspec
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/fsspec/__init__.py", line 15, in <module>
    from .mapping import FSMap, get_mapper
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 844, in exec_module
  File "<frozen importlib._bootstrap_external>", line 939, in get_code
  File "<frozen importlib._bootstrap_external>", line 1037, in get_data
KeyboardInterrupt
/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/launch.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  logger.warn(
The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run
WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.
 Please read local_rank from `os.environ('LOCAL_RANK')` instead.
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : run_summarization.py
  min_nodes        : 1
  max_nodes        : 1
  nproc_per_node   : 8
  run_id           : none
  rdzv_backend     : static
  rdzv_endpoint    : 127.0.0.1:29500
  rdzv_configs     : {'rank': 0, 'timeout': 900}
  max_restarts     : 3
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_vo7yiezb/none_iblokkt9
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:52: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=127.0.0.1
  master_port=29500
  group_rank=0
  group_world_size=1
  local_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
  role_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
  global_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
  role_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]
  global_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_vo7yiezb/none_iblokkt9/attempt_0/0/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_vo7yiezb/none_iblokkt9/attempt_0/1/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /tmp/torchelastic_vo7yiezb/none_iblokkt9/attempt_0/2/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /tmp/torchelastic_vo7yiezb/none_iblokkt9/attempt_0/3/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker4 reply file to: /tmp/torchelastic_vo7yiezb/none_iblokkt9/attempt_0/4/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker5 reply file to: /tmp/torchelastic_vo7yiezb/none_iblokkt9/attempt_0/5/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker6 reply file to: /tmp/torchelastic_vo7yiezb/none_iblokkt9/attempt_0/6/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker7 reply file to: /tmp/torchelastic_vo7yiezb/none_iblokkt9/attempt_0/7/error.json
usage: run_summarization.py [-h] --model_name_or_path MODEL_NAME_OR_PATH
                            [--config_name CONFIG_NAME]
                            [--tokenizer_name TOKENIZER_NAME]
                            [--cache_dir CACHE_DIR] [--no_use_fast_tokenizer]
                            [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                            [--model_revision MODEL_REVISION]
                            [--use_auth_token [USE_AUTH_TOKEN]]
                            [--dropout DROPOUT] [--dataset_name DATASET_NAME]
                            [--dataset_config_name DATASET_CONFIG_NAME]
                            [--text_column TEXT_COLUMN]
                            [--summary_column SUMMARY_COLUMN]
                            [--train_file TRAIN_FILE]
                            [--validation_file VALIDATION_FILE]
                            [--test_file TEST_FILE]
                            [--overwrite_cache [OVERWRITE_CACHE]]
                            [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                            [--max_source_length MAX_SOURCE_LENGTH]
                            [--max_target_length MAX_TARGET_LENGTH]
                            [--val_max_target_length VAL_MAX_TARGET_LENGTH]
                            [--no_pad_to_max_length]
                            [--pad_to_max_length [PAD_TO_MAX_LENGTH]]
                            [--max_train_samples MAX_TRAIN_SAMPLES]
                            [--max_eval_samples MAX_EVAL_SAMPLES]
                            [--max_predict_samples MAX_PREDICT_SAMPLES]
                            [--num_beams NUM_BEAMS]
                            [--no_ignore_pad_token_for_loss]
                            [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]
                            [--source_prefix SOURCE_PREFIX]
                            [--augmentor AUGMENTOR]
                            [--max_sentences MAX_SENTENCES]
                            [--mydebug [MYDEBUG]] --output_dir OUTPUT_DIR
                            [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                            [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                            [--do_predict [DO_PREDICT]]
                            [--evaluation_strategy {no,steps,epoch}]
                            [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                            [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                            [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                            [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                            [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                            [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                            [--learning_rate LEARNING_RATE]
                            [--weight_decay WEIGHT_DECAY]
                            [--adam_beta1 ADAM_BETA1]
                            [--adam_beta2 ADAM_BETA2]
                            [--adam_epsilon ADAM_EPSILON]
                            [--max_grad_norm MAX_GRAD_NORM]
                            [--num_train_epochs NUM_TRAIN_EPOCHS]
                            [--max_steps MAX_STEPS]
                            [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                            [--warmup_ratio WARMUP_RATIO]
                            [--warmup_steps WARMUP_STEPS]
                            [--log_level {debug,info,warning,error,critical,passive}]
                            [--log_level_replica {debug,info,warning,error,critical,passive}]
                            [--no_log_on_each_node]
                            [--log_on_each_node [LOG_ON_EACH_NODE]]
                            [--logging_dir LOGGING_DIR]
                            [--logging_strategy {no,steps,epoch}]
                            [--logging_first_step [LOGGING_FIRST_STEP]]
                            [--logging_steps LOGGING_STEPS]
                            [--save_strategy {no,steps,epoch}]
                            [--save_steps SAVE_STEPS]
                            [--save_total_limit SAVE_TOTAL_LIMIT]
                            [--save_on_each_node [SAVE_ON_EACH_NODE]]
                            [--no_cuda [NO_CUDA]] [--seed SEED]
                            [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]
                            [--fp16_backend {auto,amp,apex}]
                            [--fp16_full_eval [FP16_FULL_EVAL]]
                            [--local_rank LOCAL_RANK]
                            [--tpu_num_cores TPU_NUM_CORES]
                            [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                            [--debug DEBUG]
                            [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                            [--eval_steps EVAL_STEPS]
                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                            [--past_index PAST_INDEX] [--run_name RUN_NAME]
                            [--disable_tqdm DISABLE_TQDM]
                            [--no_remove_unused_columns]
                            [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                            [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                            [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                            [--greater_is_better GREATER_IS_BETTER]
                            [--ignore_data_skip [IGNORE_DATA_SKIP]]
                            [--sharded_ddp SHARDED_DDP]
                            [--deepspeed DEEPSPEED]
                            [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                            [--adafactor [ADAFACTOR]]
                            [--group_by_length [GROUP_BY_LENGTH]]
                            [--length_column_name LENGTH_COLUMN_NAME]
                            [--report_to REPORT_TO [REPORT_TO ...]]
                            [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                            [--no_dataloader_pin_memory]
                            [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                            [--no_skip_memory_metrics]
                            [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                            [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                            [--push_to_hub [PUSH_TO_HUB]]
                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                            [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                            [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                            [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                            [--mp_parameters MP_PARAMETERS]
                            [--sortish_sampler [SORTISH_SAMPLER]]
                            [--predict_with_generate [PREDICT_WITH_GENERATE]]
run_summarization.py: error: the following arguments are required: --output_dir
usage: run_summarization.py [-h] --model_name_or_path MODEL_NAME_OR_PATH
                            [--config_name CONFIG_NAME]
                            [--tokenizer_name TOKENIZER_NAME]
                            [--cache_dir CACHE_DIR] [--no_use_fast_tokenizer]
                            [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                            [--model_revision MODEL_REVISION]
                            [--use_auth_token [USE_AUTH_TOKEN]]
                            [--dropout DROPOUT] [--dataset_name DATASET_NAME]
                            [--dataset_config_name DATASET_CONFIG_NAME]
                            [--text_column TEXT_COLUMN]
                            [--summary_column SUMMARY_COLUMN]
                            [--train_file TRAIN_FILE]
                            [--validation_file VALIDATION_FILE]
                            [--test_file TEST_FILE]
                            [--overwrite_cache [OVERWRITE_CACHE]]
                            [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                            [--max_source_length MAX_SOURCE_LENGTH]
                            [--max_target_length MAX_TARGET_LENGTH]
                            [--val_max_target_length VAL_MAX_TARGET_LENGTH]
                            [--no_pad_to_max_length]
                            [--pad_to_max_length [PAD_TO_MAX_LENGTH]]
                            [--max_train_samples MAX_TRAIN_SAMPLES]
                            [--max_eval_samples MAX_EVAL_SAMPLES]
                            [--max_predict_samples MAX_PREDICT_SAMPLES]
                            [--num_beams NUM_BEAMS]
                            [--no_ignore_pad_token_for_loss]
                            [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]
                            [--source_prefix SOURCE_PREFIX]
                            [--augmentor AUGMENTOR]
                            [--max_sentences MAX_SENTENCES]
                            [--mydebug [MYDEBUG]] --output_dir OUTPUT_DIR
                            [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                            [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                            [--do_predict [DO_PREDICT]]
                            [--evaluation_strategy {no,steps,epoch}]
                            [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                            [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                            [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                            [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                            [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                            [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                            [--learning_rate LEARNING_RATE]
                            [--weight_decay WEIGHT_DECAY]
                            [--adam_beta1 ADAM_BETA1]
                            [--adam_beta2 ADAM_BETA2]
                            [--adam_epsilon ADAM_EPSILON]
                            [--max_grad_norm MAX_GRAD_NORM]
                            [--num_train_epochs NUM_TRAIN_EPOCHS]
                            [--max_steps MAX_STEPS]
                            [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                            [--warmup_ratio WARMUP_RATIO]
                            [--warmup_steps WARMUP_STEPS]
                            [--log_level {debug,info,warning,error,critical,passive}]
                            [--log_level_replica {debug,info,warning,error,critical,passive}]
                            [--no_log_on_each_node]
                            [--log_on_each_node [LOG_ON_EACH_NODE]]
                            [--logging_dir LOGGING_DIR]
                            [--logging_strategy {no,steps,epoch}]
                            [--logging_first_step [LOGGING_FIRST_STEP]]
                            [--logging_steps LOGGING_STEPS]
                            [--save_strategy {no,steps,epoch}]
                            [--save_steps SAVE_STEPS]
                            [--save_total_limit SAVE_TOTAL_LIMIT]
                            [--save_on_each_node [SAVE_ON_EACH_NODE]]
                            [--no_cuda [NO_CUDA]] [--seed SEED]
                            [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]
                            [--fp16_backend {auto,amp,apex}]
                            [--fp16_full_eval [FP16_FULL_EVAL]]
                            [--local_rank LOCAL_RANK]
                            [--tpu_num_cores TPU_NUM_CORES]
                            [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                            [--debug DEBUG]
                            [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                            [--eval_steps EVAL_STEPS]
                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                            [--past_index PAST_INDEX] [--run_name RUN_NAME]
                            [--disable_tqdm DISABLE_TQDM]
                            [--no_remove_unused_columns]
                            [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                            [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                            [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                            [--greater_is_better GREATER_IS_BETTER]
                            [--ignore_data_skip [IGNORE_DATA_SKIP]]
                            [--sharded_ddp SHARDED_DDP]
                            [--deepspeed DEEPSPEED]
                            [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                            [--adafactor [ADAFACTOR]]
                            [--group_by_length [GROUP_BY_LENGTH]]
                            [--length_column_name LENGTH_COLUMN_NAME]
                            [--report_to REPORT_TO [REPORT_TO ...]]
                            [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                            [--no_dataloader_pin_memory]
                            [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                            [--no_skip_memory_metrics]
                            [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                            [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                            [--push_to_hub [PUSH_TO_HUB]]
                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                            [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                            [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                            [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                            [--mp_parameters MP_PARAMETERS]
                            [--sortish_sampler [SORTISH_SAMPLER]]
                            [--predict_with_generate [PREDICT_WITH_GENERATE]]
run_summarization.py: error: the following arguments are required: --output_dir
usage: run_summarization.py [-h] --model_name_or_path MODEL_NAME_OR_PATH
                            [--config_name CONFIG_NAME]
                            [--tokenizer_name TOKENIZER_NAME]
                            [--cache_dir CACHE_DIR] [--no_use_fast_tokenizer]
                            [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                            [--model_revision MODEL_REVISION]
                            [--use_auth_token [USE_AUTH_TOKEN]]
                            [--dropout DROPOUT] [--dataset_name DATASET_NAME]
                            [--dataset_config_name DATASET_CONFIG_NAME]
                            [--text_column TEXT_COLUMN]
                            [--summary_column SUMMARY_COLUMN]
                            [--train_file TRAIN_FILE]
                            [--validation_file VALIDATION_FILE]
                            [--test_file TEST_FILE]
                            [--overwrite_cache [OVERWRITE_CACHE]]
                            [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                            [--max_source_length MAX_SOURCE_LENGTH]
                            [--max_target_length MAX_TARGET_LENGTH]
                            [--val_max_target_length VAL_MAX_TARGET_LENGTH]
                            [--no_pad_to_max_length]
                            [--pad_to_max_length [PAD_TO_MAX_LENGTH]]
                            [--max_train_samples MAX_TRAIN_SAMPLES]
                            [--max_eval_samples MAX_EVAL_SAMPLES]
                            [--max_predict_samples MAX_PREDICT_SAMPLES]
                            [--num_beams NUM_BEAMS]
                            [--no_ignore_pad_token_for_loss]
                            [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]
                            [--source_prefix SOURCE_PREFIX]
                            [--augmentor AUGMENTOR]
                            [--max_sentences MAX_SENTENCES]
                            [--mydebug [MYDEBUG]] --output_dir OUTPUT_DIR
                            [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                            [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                            [--do_predict [DO_PREDICT]]
                            [--evaluation_strategy {no,steps,epoch}]
                            [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                            [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                            [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                            [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                            [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                            [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                            [--learning_rate LEARNING_RATE]
                            [--weight_decay WEIGHT_DECAY]
                            [--adam_beta1 ADAM_BETA1]
                            [--adam_beta2 ADAM_BETA2]
                            [--adam_epsilon ADAM_EPSILON]
                            [--max_grad_norm MAX_GRAD_NORM]
                            [--num_train_epochs NUM_TRAIN_EPOCHS]
                            [--max_steps MAX_STEPS]
                            [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                            [--warmup_ratio WARMUP_RATIO]
                            [--warmup_steps WARMUP_STEPS]
                            [--log_level {debug,info,warning,error,critical,passive}]
                            [--log_level_replica {debug,info,warning,error,critical,passive}]
                            [--no_log_on_each_node]
                            [--log_on_each_node [LOG_ON_EACH_NODE]]
                            [--logging_dir LOGGING_DIR]
                            [--logging_strategy {no,steps,epoch}]
                            [--logging_first_step [LOGGING_FIRST_STEP]]
                            [--logging_steps LOGGING_STEPS]
                            [--save_strategy {no,steps,epoch}]
                            [--save_steps SAVE_STEPS]
                            [--save_total_limit SAVE_TOTAL_LIMIT]
                            [--save_on_each_node [SAVE_ON_EACH_NODE]]
                            [--no_cuda [NO_CUDA]] [--seed SEED]
                            [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]
                            [--fp16_backend {auto,amp,apex}]
                            [--fp16_full_eval [FP16_FULL_EVAL]]
                            [--local_rank LOCAL_RANK]
                            [--tpu_num_cores TPU_NUM_CORES]
                            [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                            [--debug DEBUG]
                            [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                            [--eval_steps EVAL_STEPS]
                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                            [--past_index PAST_INDEX] [--run_name RUN_NAME]
                            [--disable_tqdm DISABLE_TQDM]
                            [--no_remove_unused_columns]
                            [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                            [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                            [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                            [--greater_is_better GREATER_IS_BETTER]
                            [--ignore_data_skip [IGNORE_DATA_SKIP]]
                            [--sharded_ddp SHARDED_DDP]
                            [--deepspeed DEEPSPEED]
                            [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                            [--adafactor [ADAFACTOR]]
                            [--group_by_length [GROUP_BY_LENGTH]]
                            [--length_column_name LENGTH_COLUMN_NAME]
                            [--report_to REPORT_TO [REPORT_TO ...]]
                            [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                            [--no_dataloader_pin_memory]
                            [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                            [--no_skip_memory_metrics]
                            [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                            [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                            [--push_to_hub [PUSH_TO_HUB]]
                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                            [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                            [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                            [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                            [--mp_parameters MP_PARAMETERS]
                            [--sortish_sampler [SORTISH_SAMPLER]]
                            [--predict_with_generate [PREDICT_WITH_GENERATE]]
run_summarization.py: error: the following arguments are required: --output_dir
usage: run_summarization.py [-h] --model_name_or_path MODEL_NAME_OR_PATH
                            [--config_name CONFIG_NAME]
                            [--tokenizer_name TOKENIZER_NAME]
                            [--cache_dir CACHE_DIR] [--no_use_fast_tokenizer]
                            [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                            [--model_revision MODEL_REVISION]
                            [--use_auth_token [USE_AUTH_TOKEN]]
                            [--dropout DROPOUT] [--dataset_name DATASET_NAME]
                            [--dataset_config_name DATASET_CONFIG_NAME]
                            [--text_column TEXT_COLUMN]
                            [--summary_column SUMMARY_COLUMN]
                            [--train_file TRAIN_FILE]
                            [--validation_file VALIDATION_FILE]
                            [--test_file TEST_FILE]
                            [--overwrite_cache [OVERWRITE_CACHE]]
                            [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                            [--max_source_length MAX_SOURCE_LENGTH]
                            [--max_target_length MAX_TARGET_LENGTH]
                            [--val_max_target_length VAL_MAX_TARGET_LENGTH]
                            [--no_pad_to_max_length]
                            [--pad_to_max_length [PAD_TO_MAX_LENGTH]]
                            [--max_train_samples MAX_TRAIN_SAMPLES]
                            [--max_eval_samples MAX_EVAL_SAMPLES]
                            [--max_predict_samples MAX_PREDICT_SAMPLES]
                            [--num_beams NUM_BEAMS]
                            [--no_ignore_pad_token_for_loss]
                            [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]
                            [--source_prefix SOURCE_PREFIX]
                            [--augmentor AUGMENTOR]
                            [--max_sentences MAX_SENTENCES]
                            [--mydebug [MYDEBUG]] --output_dir OUTPUT_DIR
                            [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                            [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                            [--do_predict [DO_PREDICT]]
                            [--evaluation_strategy {no,steps,epoch}]
                            [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                            [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                            [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                            [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                            [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                            [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                            [--learning_rate LEARNING_RATE]
                            [--weight_decay WEIGHT_DECAY]
                            [--adam_beta1 ADAM_BETA1]
                            [--adam_beta2 ADAM_BETA2]
                            [--adam_epsilon ADAM_EPSILON]
                            [--max_grad_norm MAX_GRAD_NORM]
                            [--num_train_epochs NUM_TRAIN_EPOCHS]
                            [--max_steps MAX_STEPS]
                            [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                            [--warmup_ratio WARMUP_RATIO]
                            [--warmup_steps WARMUP_STEPS]
                            [--log_level {debug,info,warning,error,critical,passive}]
                            [--log_level_replica {debug,info,warning,error,critical,passive}]
                            [--no_log_on_each_node]
                            [--log_on_each_node [LOG_ON_EACH_NODE]]
                            [--logging_dir LOGGING_DIR]
                            [--logging_strategy {no,steps,epoch}]
                            [--logging_first_step [LOGGING_FIRST_STEP]]
                            [--logging_steps LOGGING_STEPS]
                            [--save_strategy {no,steps,epoch}]
                            [--save_steps SAVE_STEPS]
                            [--save_total_limit SAVE_TOTAL_LIMIT]
                            [--save_on_each_node [SAVE_ON_EACH_NODE]]
                            [--no_cuda [NO_CUDA]] [--seed SEED]
                            [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]
                            [--fp16_backend {auto,amp,apex}]
                            [--fp16_full_eval [FP16_FULL_EVAL]]
                            [--local_rank LOCAL_RANK]
                            [--tpu_num_cores TPU_NUM_CORES]
                            [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                            [--debug DEBUG]
                            [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                            [--eval_steps EVAL_STEPS]
                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                            [--past_index PAST_INDEX] [--run_name RUN_NAME]
                            [--disable_tqdm DISABLE_TQDM]
                            [--no_remove_unused_columns]
                            [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                            [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                            [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                            [--greater_is_better GREATER_IS_BETTER]
                            [--ignore_data_skip [IGNORE_DATA_SKIP]]
                            [--sharded_ddp SHARDED_DDP]
                            [--deepspeed DEEPSPEED]
                            [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                            [--adafactor [ADAFACTOR]]
                            [--group_by_length [GROUP_BY_LENGTH]]
                            [--length_column_name LENGTH_COLUMN_NAME]
                            [--report_to REPORT_TO [REPORT_TO ...]]
                            [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                            [--no_dataloader_pin_memory]
                            [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                            [--no_skip_memory_metrics]
                            [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                            [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                            [--push_to_hub [PUSH_TO_HUB]]
                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                            [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                            [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                            [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                            [--mp_parameters MP_PARAMETERS]
                            [--sortish_sampler [SORTISH_SAMPLER]]
                            [--predict_with_generate [PREDICT_WITH_GENERATE]]
run_summarization.py: error: the following arguments are required: --output_dir
usage: run_summarization.py [-h] --model_name_or_path MODEL_NAME_OR_PATH
                            [--config_name CONFIG_NAME]
                            [--tokenizer_name TOKENIZER_NAME]
                            [--cache_dir CACHE_DIR] [--no_use_fast_tokenizer]
                            [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                            [--model_revision MODEL_REVISION]
                            [--use_auth_token [USE_AUTH_TOKEN]]
                            [--dropout DROPOUT] [--dataset_name DATASET_NAME]
                            [--dataset_config_name DATASET_CONFIG_NAME]
                            [--text_column TEXT_COLUMN]
                            [--summary_column SUMMARY_COLUMN]
                            [--train_file TRAIN_FILE]
                            [--validation_file VALIDATION_FILE]
                            [--test_file TEST_FILE]
                            [--overwrite_cache [OVERWRITE_CACHE]]
                            [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                            [--max_source_length MAX_SOURCE_LENGTH]
                            [--max_target_length MAX_TARGET_LENGTH]
                            [--val_max_target_length VAL_MAX_TARGET_LENGTH]
                            [--no_pad_to_max_length]
                            [--pad_to_max_length [PAD_TO_MAX_LENGTH]]
                            [--max_train_samples MAX_TRAIN_SAMPLES]
                            [--max_eval_samples MAX_EVAL_SAMPLES]
                            [--max_predict_samples MAX_PREDICT_SAMPLES]
                            [--num_beams NUM_BEAMS]
                            [--no_ignore_pad_token_for_loss]
                            [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]
                            [--source_prefix SOURCE_PREFIX]
                            [--augmentor AUGMENTOR]
                            [--max_sentences MAX_SENTENCES]
                            [--mydebug [MYDEBUG]] --output_dir OUTPUT_DIR
                            [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                            [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                            [--do_predict [DO_PREDICT]]
                            [--evaluation_strategy {no,steps,epoch}]
                            [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                            [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                            [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                            [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                            [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                            [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                            [--learning_rate LEARNING_RATE]
                            [--weight_decay WEIGHT_DECAY]
                            [--adam_beta1 ADAM_BETA1]
                            [--adam_beta2 ADAM_BETA2]
                            [--adam_epsilon ADAM_EPSILON]
                            [--max_grad_norm MAX_GRAD_NORM]
                            [--num_train_epochs NUM_TRAIN_EPOCHS]
                            [--max_steps MAX_STEPS]
                            [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                            [--warmup_ratio WARMUP_RATIO]
                            [--warmup_steps WARMUP_STEPS]
                            [--log_level {debug,info,warning,error,critical,passive}]
                            [--log_level_replica {debug,info,warning,error,critical,passive}]
                            [--no_log_on_each_node]
                            [--log_on_each_node [LOG_ON_EACH_NODE]]
                            [--logging_dir LOGGING_DIR]
                            [--logging_strategy {no,steps,epoch}]
                            [--logging_first_step [LOGGING_FIRST_STEP]]
                            [--logging_steps LOGGING_STEPS]
                            [--save_strategy {no,steps,epoch}]
                            [--save_steps SAVE_STEPS]
                            [--save_total_limit SAVE_TOTAL_LIMIT]
                            [--save_on_each_node [SAVE_ON_EACH_NODE]]
                            [--no_cuda [NO_CUDA]] [--seed SEED]
                            [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]
                            [--fp16_backend {auto,amp,apex}]
                            [--fp16_full_eval [FP16_FULL_EVAL]]
                            [--local_rank LOCAL_RANK]
                            [--tpu_num_cores TPU_NUM_CORES]
                            [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                            [--debug DEBUG]
                            [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                            [--eval_steps EVAL_STEPS]
                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                            [--past_index PAST_INDEX] [--run_name RUN_NAME]
                            [--disable_tqdm DISABLE_TQDM]
                            [--no_remove_unused_columns]
                            [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                            [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                            [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                            [--greater_is_better GREATER_IS_BETTER]
                            [--ignore_data_skip [IGNORE_DATA_SKIP]]
                            [--sharded_ddp SHARDED_DDP]
                            [--deepspeed DEEPSPEED]
                            [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                            [--adafactor [ADAFACTOR]]
                            [--group_by_length [GROUP_BY_LENGTH]]
                            [--length_column_name LENGTH_COLUMN_NAME]
                            [--report_to REPORT_TO [REPORT_TO ...]]
                            [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                            [--no_dataloader_pin_memory]
                            [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                            [--no_skip_memory_metrics]
                            [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                            [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                            [--push_to_hub [PUSH_TO_HUB]]
                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                            [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                            [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                            [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                            [--mp_parameters MP_PARAMETERS]
                            [--sortish_sampler [SORTISH_SAMPLER]]
                            [--predict_with_generate [PREDICT_WITH_GENERATE]]
usage: run_summarization.py [-h] --model_name_or_path MODEL_NAME_OR_PATH
                            [--config_name CONFIG_NAME]
                            [--tokenizer_name TOKENIZER_NAME]
                            [--cache_dir CACHE_DIR] [--no_use_fast_tokenizer]
                            [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                            [--model_revision MODEL_REVISION]
                            [--use_auth_token [USE_AUTH_TOKEN]]
                            [--dropout DROPOUT] [--dataset_name DATASET_NAME]
                            [--dataset_config_name DATASET_CONFIG_NAME]
                            [--text_column TEXT_COLUMN]
                            [--summary_column SUMMARY_COLUMN]
                            [--train_file TRAIN_FILE]
                            [--validation_file VALIDATION_FILE]
                            [--test_file TEST_FILE]
                            [--overwrite_cache [OVERWRITE_CACHE]]
                            [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                            [--max_source_length MAX_SOURCE_LENGTH]
                            [--max_target_length MAX_TARGET_LENGTH]
                            [--val_max_target_length VAL_MAX_TARGET_LENGTH]
                            [--no_pad_to_max_length]
                            [--pad_to_max_length [PAD_TO_MAX_LENGTH]]
                            [--max_train_samples MAX_TRAIN_SAMPLES]
                            [--max_eval_samples MAX_EVAL_SAMPLES]
                            [--max_predict_samples MAX_PREDICT_SAMPLES]
                            [--num_beams NUM_BEAMS]
                            [--no_ignore_pad_token_for_loss]
                            [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]
                            [--source_prefix SOURCE_PREFIX]
                            [--augmentor AUGMENTOR]
                            [--max_sentences MAX_SENTENCES]
                            [--mydebug [MYDEBUG]] --output_dir OUTPUT_DIR
                            [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                            [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                            [--do_predict [DO_PREDICT]]
                            [--evaluation_strategy {no,steps,epoch}]
                            [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                            [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                            [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                            [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                            [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                            [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                            [--learning_rate LEARNING_RATE]
                            [--weight_decay WEIGHT_DECAY]
                            [--adam_beta1 ADAM_BETA1]
                            [--adam_beta2 ADAM_BETA2]
                            [--adam_epsilon ADAM_EPSILON]
                            [--max_grad_norm MAX_GRAD_NORM]
                            [--num_train_epochs NUM_TRAIN_EPOCHS]
                            [--max_steps MAX_STEPS]
                            [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                            [--warmup_ratio WARMUP_RATIO]
                            [--warmup_steps WARMUP_STEPS]
                            [--log_level {debug,info,warning,error,critical,passive}]
                            [--log_level_replica {debug,info,warning,error,critical,passive}]
                            [--no_log_on_each_node]
                            [--log_on_each_node [LOG_ON_EACH_NODE]]
                            [--logging_dir LOGGING_DIR]
                            [--logging_strategy {no,steps,epoch}]
                            [--logging_first_step [LOGGING_FIRST_STEP]]
                            [--logging_steps LOGGING_STEPS]
                            [--save_strategy {no,steps,epoch}]
                            [--save_steps SAVE_STEPS]
                            [--save_total_limit SAVE_TOTAL_LIMIT]
                            [--save_on_each_node [SAVE_ON_EACH_NODE]]
                            [--no_cuda [NO_CUDA]] [--seed SEED]
                            [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]
                            [--fp16_backend {auto,amp,apex}]
                            [--fp16_full_eval [FP16_FULL_EVAL]]
                            [--local_rank LOCAL_RANK]
                            [--tpu_num_cores TPU_NUM_CORES]
                            [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                            [--debug DEBUG]
                            [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                            [--eval_steps EVAL_STEPS]
                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                            [--past_index PAST_INDEX] [--run_name RUN_NAME]
                            [--disable_tqdm DISABLE_TQDM]
                            [--no_remove_unused_columns]
                            [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                            [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                            [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                            [--greater_is_better GREATER_IS_BETTER]
                            [--ignore_data_skip [IGNORE_DATA_SKIP]]
                            [--sharded_ddp SHARDED_DDP]
                            [--deepspeed DEEPSPEED]
                            [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                            [--adafactor [ADAFACTOR]]
                            [--group_by_length [GROUP_BY_LENGTH]]
                            [--length_column_name LENGTH_COLUMN_NAME]
                            [--report_to REPORT_TO [REPORT_TO ...]]
                            [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                            [--no_dataloader_pin_memory]
                            [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                            [--no_skip_memory_metrics]
                            [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                            [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                            [--push_to_hub [PUSH_TO_HUB]]
                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                            [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                            [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                            [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                            [--mp_parameters MP_PARAMETERS]
                            [--sortish_sampler [SORTISH_SAMPLER]]
                            [--predict_with_generate [PREDICT_WITH_GENERATE]]
run_summarization.py: error: the following arguments are required: --output_dir
run_summarization.py: error: the following arguments are required: --output_dir
usage: run_summarization.py [-h] --model_name_or_path MODEL_NAME_OR_PATH
                            [--config_name CONFIG_NAME]
                            [--tokenizer_name TOKENIZER_NAME]
                            [--cache_dir CACHE_DIR] [--no_use_fast_tokenizer]
                            [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                            [--model_revision MODEL_REVISION]
                            [--use_auth_token [USE_AUTH_TOKEN]]
                            [--dropout DROPOUT] [--dataset_name DATASET_NAME]
                            [--dataset_config_name DATASET_CONFIG_NAME]
                            [--text_column TEXT_COLUMN]
                            [--summary_column SUMMARY_COLUMN]
                            [--train_file TRAIN_FILE]
                            [--validation_file VALIDATION_FILE]
                            [--test_file TEST_FILE]
                            [--overwrite_cache [OVERWRITE_CACHE]]
                            [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                            [--max_source_length MAX_SOURCE_LENGTH]
                            [--max_target_length MAX_TARGET_LENGTH]
                            [--val_max_target_length VAL_MAX_TARGET_LENGTH]
                            [--no_pad_to_max_length]
                            [--pad_to_max_length [PAD_TO_MAX_LENGTH]]
                            [--max_train_samples MAX_TRAIN_SAMPLES]
                            [--max_eval_samples MAX_EVAL_SAMPLES]
                            [--max_predict_samples MAX_PREDICT_SAMPLES]
                            [--num_beams NUM_BEAMS]
                            [--no_ignore_pad_token_for_loss]
                            [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]
                            [--source_prefix SOURCE_PREFIX]
                            [--augmentor AUGMENTOR]
                            [--max_sentences MAX_SENTENCES]
                            [--mydebug [MYDEBUG]] --output_dir OUTPUT_DIR
                            [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                            [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                            [--do_predict [DO_PREDICT]]
                            [--evaluation_strategy {no,steps,epoch}]
                            [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                            [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                            [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                            [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                            [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                            [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                            [--learning_rate LEARNING_RATE]
                            [--weight_decay WEIGHT_DECAY]
                            [--adam_beta1 ADAM_BETA1]
                            [--adam_beta2 ADAM_BETA2]
                            [--adam_epsilon ADAM_EPSILON]
                            [--max_grad_norm MAX_GRAD_NORM]
                            [--num_train_epochs NUM_TRAIN_EPOCHS]
                            [--max_steps MAX_STEPS]
                            [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                            [--warmup_ratio WARMUP_RATIO]
                            [--warmup_steps WARMUP_STEPS]
                            [--log_level {debug,info,warning,error,critical,passive}]
                            [--log_level_replica {debug,info,warning,error,critical,passive}]
                            [--no_log_on_each_node]
                            [--log_on_each_node [LOG_ON_EACH_NODE]]
                            [--logging_dir LOGGING_DIR]
                            [--logging_strategy {no,steps,epoch}]
                            [--logging_first_step [LOGGING_FIRST_STEP]]
                            [--logging_steps LOGGING_STEPS]
                            [--save_strategy {no,steps,epoch}]
                            [--save_steps SAVE_STEPS]
                            [--save_total_limit SAVE_TOTAL_LIMIT]
                            [--save_on_each_node [SAVE_ON_EACH_NODE]]
                            [--no_cuda [NO_CUDA]] [--seed SEED]
                            [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]
                            [--fp16_backend {auto,amp,apex}]
                            [--fp16_full_eval [FP16_FULL_EVAL]]
                            [--local_rank LOCAL_RANK]
                            [--tpu_num_cores TPU_NUM_CORES]
                            [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                            [--debug DEBUG]
                            [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                            [--eval_steps EVAL_STEPS]
                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                            [--past_index PAST_INDEX] [--run_name RUN_NAME]
                            [--disable_tqdm DISABLE_TQDM]
                            [--no_remove_unused_columns]
                            [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                            [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                            [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                            [--greater_is_better GREATER_IS_BETTER]
                            [--ignore_data_skip [IGNORE_DATA_SKIP]]
                            [--sharded_ddp SHARDED_DDP]
                            [--deepspeed DEEPSPEED]
                            [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                            [--adafactor [ADAFACTOR]]
                            [--group_by_length [GROUP_BY_LENGTH]]
                            [--length_column_name LENGTH_COLUMN_NAME]
                            [--report_to REPORT_TO [REPORT_TO ...]]
                            [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                            [--no_dataloader_pin_memory]
                            [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                            [--no_skip_memory_metrics]
                            [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                            [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                            [--push_to_hub [PUSH_TO_HUB]]
                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                            [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                            [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                            [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                            [--mp_parameters MP_PARAMETERS]
                            [--sortish_sampler [SORTISH_SAMPLER]]
                            [--predict_with_generate [PREDICT_WITH_GENERATE]]
run_summarization.py: error: the following arguments are required: --output_dir
usage: run_summarization.py [-h] --model_name_or_path MODEL_NAME_OR_PATH
                            [--config_name CONFIG_NAME]
                            [--tokenizer_name TOKENIZER_NAME]
                            [--cache_dir CACHE_DIR] [--no_use_fast_tokenizer]
                            [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                            [--model_revision MODEL_REVISION]
                            [--use_auth_token [USE_AUTH_TOKEN]]
                            [--dropout DROPOUT] [--dataset_name DATASET_NAME]
                            [--dataset_config_name DATASET_CONFIG_NAME]
                            [--text_column TEXT_COLUMN]
                            [--summary_column SUMMARY_COLUMN]
                            [--train_file TRAIN_FILE]
                            [--validation_file VALIDATION_FILE]
                            [--test_file TEST_FILE]
                            [--overwrite_cache [OVERWRITE_CACHE]]
                            [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                            [--max_source_length MAX_SOURCE_LENGTH]
                            [--max_target_length MAX_TARGET_LENGTH]
                            [--val_max_target_length VAL_MAX_TARGET_LENGTH]
                            [--no_pad_to_max_length]
                            [--pad_to_max_length [PAD_TO_MAX_LENGTH]]
                            [--max_train_samples MAX_TRAIN_SAMPLES]
                            [--max_eval_samples MAX_EVAL_SAMPLES]
                            [--max_predict_samples MAX_PREDICT_SAMPLES]
                            [--num_beams NUM_BEAMS]
                            [--no_ignore_pad_token_for_loss]
                            [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]
                            [--source_prefix SOURCE_PREFIX]
                            [--augmentor AUGMENTOR]
                            [--max_sentences MAX_SENTENCES]
                            [--mydebug [MYDEBUG]] --output_dir OUTPUT_DIR
                            [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                            [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                            [--do_predict [DO_PREDICT]]
                            [--evaluation_strategy {no,steps,epoch}]
                            [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                            [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                            [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                            [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                            [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                            [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                            [--learning_rate LEARNING_RATE]
                            [--weight_decay WEIGHT_DECAY]
                            [--adam_beta1 ADAM_BETA1]
                            [--adam_beta2 ADAM_BETA2]
                            [--adam_epsilon ADAM_EPSILON]
                            [--max_grad_norm MAX_GRAD_NORM]
                            [--num_train_epochs NUM_TRAIN_EPOCHS]
                            [--max_steps MAX_STEPS]
                            [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                            [--warmup_ratio WARMUP_RATIO]
                            [--warmup_steps WARMUP_STEPS]
                            [--log_level {debug,info,warning,error,critical,passive}]
                            [--log_level_replica {debug,info,warning,error,critical,passive}]
                            [--no_log_on_each_node]
                            [--log_on_each_node [LOG_ON_EACH_NODE]]
                            [--logging_dir LOGGING_DIR]
                            [--logging_strategy {no,steps,epoch}]
                            [--logging_first_step [LOGGING_FIRST_STEP]]
                            [--logging_steps LOGGING_STEPS]
                            [--save_strategy {no,steps,epoch}]
                            [--save_steps SAVE_STEPS]
                            [--save_total_limit SAVE_TOTAL_LIMIT]
                            [--save_on_each_node [SAVE_ON_EACH_NODE]]
                            [--no_cuda [NO_CUDA]] [--seed SEED]
                            [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]
                            [--fp16_backend {auto,amp,apex}]
                            [--fp16_full_eval [FP16_FULL_EVAL]]
                            [--local_rank LOCAL_RANK]
                            [--tpu_num_cores TPU_NUM_CORES]
                            [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                            [--debug DEBUG]
                            [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                            [--eval_steps EVAL_STEPS]
                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                            [--past_index PAST_INDEX] [--run_name RUN_NAME]
                            [--disable_tqdm DISABLE_TQDM]
                            [--no_remove_unused_columns]
                            [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                            [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                            [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                            [--greater_is_better GREATER_IS_BETTER]
                            [--ignore_data_skip [IGNORE_DATA_SKIP]]
                            [--sharded_ddp SHARDED_DDP]
                            [--deepspeed DEEPSPEED]
                            [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                            [--adafactor [ADAFACTOR]]
                            [--group_by_length [GROUP_BY_LENGTH]]
                            [--length_column_name LENGTH_COLUMN_NAME]
                            [--report_to REPORT_TO [REPORT_TO ...]]
                            [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                            [--no_dataloader_pin_memory]
                            [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                            [--no_skip_memory_metrics]
                            [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                            [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                            [--push_to_hub [PUSH_TO_HUB]]
                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                            [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                            [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                            [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                            [--mp_parameters MP_PARAMETERS]
                            [--sortish_sampler [SORTISH_SAMPLER]]
                            [--predict_with_generate [PREDICT_WITH_GENERATE]]
run_summarization.py: error: the following arguments are required: --output_dir
Traceback (most recent call last):
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/launch.py", line 173, in <module>
    main()
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/launch.py", line 169, in main
    run(args)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/run.py", line 621, in run
    elastic_launch(
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 116, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 238, in launch_agent
    result = agent.run()
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/elastic/metrics/api.py", line 125, in wrapper
    result = f(*args, **kwargs)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 700, in run
    result = self._invoke_run(role)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 828, in _invoke_run
    time.sleep(monitor_interval)
KeyboardInterrupt
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/launch.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  logger.warn(
The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run
WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.
 Please read local_rank from `os.environ('LOCAL_RANK')` instead.
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : run_summarization.py
  min_nodes        : 1
  max_nodes        : 1
  nproc_per_node   : 8
  run_id           : none
  rdzv_backend     : static
  rdzv_endpoint    : 127.0.0.1:29500
  rdzv_configs     : {'rank': 0, 'timeout': 900}
  max_restarts     : 3
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_5mjucvs5/none_6nek00ej
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:52: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=127.0.0.1
  master_port=29500
  group_rank=0
  group_world_size=1
  local_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
  role_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
  global_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
  role_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]
  global_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_5mjucvs5/none_6nek00ej/attempt_0/0/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_5mjucvs5/none_6nek00ej/attempt_0/1/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /tmp/torchelastic_5mjucvs5/none_6nek00ej/attempt_0/2/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /tmp/torchelastic_5mjucvs5/none_6nek00ej/attempt_0/3/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker4 reply file to: /tmp/torchelastic_5mjucvs5/none_6nek00ej/attempt_0/4/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker5 reply file to: /tmp/torchelastic_5mjucvs5/none_6nek00ej/attempt_0/5/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker6 reply file to: /tmp/torchelastic_5mjucvs5/none_6nek00ej/attempt_0/6/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker7 reply file to: /tmp/torchelastic_5mjucvs5/none_6nek00ej/attempt_0/7/error.json
usage: run_summarization.py [-h] --model_name_or_path MODEL_NAME_OR_PATH
                            [--config_name CONFIG_NAME]
                            [--tokenizer_name TOKENIZER_NAME]
                            [--cache_dir CACHE_DIR] [--no_use_fast_tokenizer]
                            [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                            [--model_revision MODEL_REVISION]
                            [--use_auth_token [USE_AUTH_TOKEN]]
                            [--dropout DROPOUT] [--dataset_name DATASET_NAME]
                            [--dataset_config_name DATASET_CONFIG_NAME]
                            [--text_column TEXT_COLUMN]
                            [--summary_column SUMMARY_COLUMN]
                            [--train_file TRAIN_FILE]
                            [--validation_file VALIDATION_FILE]
                            [--test_file TEST_FILE]
                            [--overwrite_cache [OVERWRITE_CACHE]]
                            [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                            [--max_source_length MAX_SOURCE_LENGTH]
                            [--max_target_length MAX_TARGET_LENGTH]
                            [--val_max_target_length VAL_MAX_TARGET_LENGTH]
                            [--no_pad_to_max_length]
                            [--pad_to_max_length [PAD_TO_MAX_LENGTH]]
                            [--max_train_samples MAX_TRAIN_SAMPLES]
                            [--max_eval_samples MAX_EVAL_SAMPLES]
                            [--max_predict_samples MAX_PREDICT_SAMPLES]
                            [--num_beams NUM_BEAMS]
                            [--no_ignore_pad_token_for_loss]
                            [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]
                            [--source_prefix SOURCE_PREFIX]
                            [--augmentor AUGMENTOR]
                            [--max_sentences MAX_SENTENCES]
                            [--mydebug [MYDEBUG]] --output_dir OUTPUT_DIR
                            [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                            [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                            [--do_predict [DO_PREDICT]]
                            [--evaluation_strategy {no,steps,epoch}]
                            [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                            [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                            [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                            [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                            [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                            [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                            [--learning_rate LEARNING_RATE]
                            [--weight_decay WEIGHT_DECAY]
                            [--adam_beta1 ADAM_BETA1]
                            [--adam_beta2 ADAM_BETA2]
                            [--adam_epsilon ADAM_EPSILON]
                            [--max_grad_norm MAX_GRAD_NORM]
                            [--num_train_epochs NUM_TRAIN_EPOCHS]
                            [--max_steps MAX_STEPS]
                            [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                            [--warmup_ratio WARMUP_RATIO]
                            [--warmup_steps WARMUP_STEPS]
                            [--log_level {debug,info,warning,error,critical,passive}]
                            [--log_level_replica {debug,info,warning,error,critical,passive}]
                            [--no_log_on_each_node]
                            [--log_on_each_node [LOG_ON_EACH_NODE]]
                            [--logging_dir LOGGING_DIR]
                            [--logging_strategy {no,steps,epoch}]
                            [--logging_first_step [LOGGING_FIRST_STEP]]
                            [--logging_steps LOGGING_STEPS]
                            [--save_strategy {no,steps,epoch}]
                            [--save_steps SAVE_STEPS]
                            [--save_total_limit SAVE_TOTAL_LIMIT]
                            [--save_on_each_node [SAVE_ON_EACH_NODE]]
                            [--no_cuda [NO_CUDA]] [--seed SEED]
                            [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]
                            [--fp16_backend {auto,amp,apex}]
                            [--fp16_full_eval [FP16_FULL_EVAL]]
                            [--local_rank LOCAL_RANK]
                            [--tpu_num_cores TPU_NUM_CORES]
                            [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                            [--debug DEBUG]
                            [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                            [--eval_steps EVAL_STEPS]
                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                            [--past_index PAST_INDEX] [--run_name RUN_NAME]
                            [--disable_tqdm DISABLE_TQDM]
                            [--no_remove_unused_columns]
                            [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                            [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                            [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                            [--greater_is_better GREATER_IS_BETTER]
                            [--ignore_data_skip [IGNORE_DATA_SKIP]]
                            [--sharded_ddp SHARDED_DDP]
                            [--deepspeed DEEPSPEED]
                            [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                            [--adafactor [ADAFACTOR]]
                            [--group_by_length [GROUP_BY_LENGTH]]
                            [--length_column_name LENGTH_COLUMN_NAME]
                            [--report_to REPORT_TO [REPORT_TO ...]]
                            [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                            [--no_dataloader_pin_memory]
                            [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                            [--no_skip_memory_metrics]
                            [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                            [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                            [--push_to_hub [PUSH_TO_HUB]]
                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                            [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                            [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                            [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                            [--mp_parameters MP_PARAMETERS]
                            [--sortish_sampler [SORTISH_SAMPLER]]
                            [--predict_with_generate [PREDICT_WITH_GENERATE]]
run_summarization.py: error: argument --predict_with_generate: Truthy value expected: got > but expected one of yes/no, true/false, t/f, y/n, 1/0 (case insensitive).
usage: run_summarization.py [-h] --model_name_or_path MODEL_NAME_OR_PATH
                            [--config_name CONFIG_NAME]
                            [--tokenizer_name TOKENIZER_NAME]
                            [--cache_dir CACHE_DIR] [--no_use_fast_tokenizer]
                            [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                            [--model_revision MODEL_REVISION]
                            [--use_auth_token [USE_AUTH_TOKEN]]
                            [--dropout DROPOUT] [--dataset_name DATASET_NAME]
                            [--dataset_config_name DATASET_CONFIG_NAME]
                            [--text_column TEXT_COLUMN]
                            [--summary_column SUMMARY_COLUMN]
                            [--train_file TRAIN_FILE]
                            [--validation_file VALIDATION_FILE]
                            [--test_file TEST_FILE]
                            [--overwrite_cache [OVERWRITE_CACHE]]
                            [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                            [--max_source_length MAX_SOURCE_LENGTH]
                            [--max_target_length MAX_TARGET_LENGTH]
                            [--val_max_target_length VAL_MAX_TARGET_LENGTH]
                            [--no_pad_to_max_length]
                            [--pad_to_max_length [PAD_TO_MAX_LENGTH]]
                            [--max_train_samples MAX_TRAIN_SAMPLES]
                            [--max_eval_samples MAX_EVAL_SAMPLES]
                            [--max_predict_samples MAX_PREDICT_SAMPLES]
                            [--num_beams NUM_BEAMS]
                            [--no_ignore_pad_token_for_loss]
                            [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]
                            [--source_prefix SOURCE_PREFIX]
                            [--augmentor AUGMENTOR]
                            [--max_sentences MAX_SENTENCES]
                            [--mydebug [MYDEBUG]] --output_dir OUTPUT_DIR
                            [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                            [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                            [--do_predict [DO_PREDICT]]
                            [--evaluation_strategy {no,steps,epoch}]
                            [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                            [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                            [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                            [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                            [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                            [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                            [--learning_rate LEARNING_RATE]
                            [--weight_decay WEIGHT_DECAY]
                            [--adam_beta1 ADAM_BETA1]
                            [--adam_beta2 ADAM_BETA2]
                            [--adam_epsilon ADAM_EPSILON]
                            [--max_grad_norm MAX_GRAD_NORM]
                            [--num_train_epochs NUM_TRAIN_EPOCHS]
                            [--max_steps MAX_STEPS]
                            [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                            [--warmup_ratio WARMUP_RATIO]
                            [--warmup_steps WARMUP_STEPS]
                            [--log_level {debug,info,warning,error,critical,passive}]
                            [--log_level_replica {debug,info,warning,error,critical,passive}]
                            [--no_log_on_each_node]
                            [--log_on_each_node [LOG_ON_EACH_NODE]]
                            [--logging_dir LOGGING_DIR]
                            [--logging_strategy {no,steps,epoch}]
                            [--logging_first_step [LOGGING_FIRST_STEP]]
                            [--logging_steps LOGGING_STEPS]
                            [--save_strategy {no,steps,epoch}]
                            [--save_steps SAVE_STEPS]
                            [--save_total_limit SAVE_TOTAL_LIMIT]
                            [--save_on_each_node [SAVE_ON_EACH_NODE]]
                            [--no_cuda [NO_CUDA]] [--seed SEED]
                            [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]
                            [--fp16_backend {auto,amp,apex}]
                            [--fp16_full_eval [FP16_FULL_EVAL]]
                            [--local_rank LOCAL_RANK]
                            [--tpu_num_cores TPU_NUM_CORES]
                            [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                            [--debug DEBUG]
                            [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                            [--eval_steps EVAL_STEPS]
                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                            [--past_index PAST_INDEX] [--run_name RUN_NAME]
                            [--disable_tqdm DISABLE_TQDM]
                            [--no_remove_unused_columns]
                            [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                            [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                            [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                            [--greater_is_better GREATER_IS_BETTER]
                            [--ignore_data_skip [IGNORE_DATA_SKIP]]
                            [--sharded_ddp SHARDED_DDP]
                            [--deepspeed DEEPSPEED]
                            [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                            [--adafactor [ADAFACTOR]]
                            [--group_by_length [GROUP_BY_LENGTH]]
                            [--length_column_name LENGTH_COLUMN_NAME]
                            [--report_to REPORT_TO [REPORT_TO ...]]
                            [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                            [--no_dataloader_pin_memory]
                            [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                            [--no_skip_memory_metrics]
                            [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                            [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                            [--push_to_hub [PUSH_TO_HUB]]
                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                            [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                            [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                            [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                            [--mp_parameters MP_PARAMETERS]
                            [--sortish_sampler [SORTISH_SAMPLER]]
                            [--predict_with_generate [PREDICT_WITH_GENERATE]]
run_summarization.py: error: argument --predict_with_generate: Truthy value expected: got > but expected one of yes/no, true/false, t/f, y/n, 1/0 (case insensitive).
usage: run_summarization.py [-h] --model_name_or_path MODEL_NAME_OR_PATH
                            [--config_name CONFIG_NAME]
                            [--tokenizer_name TOKENIZER_NAME]
                            [--cache_dir CACHE_DIR] [--no_use_fast_tokenizer]
                            [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                            [--model_revision MODEL_REVISION]
                            [--use_auth_token [USE_AUTH_TOKEN]]
                            [--dropout DROPOUT] [--dataset_name DATASET_NAME]
                            [--dataset_config_name DATASET_CONFIG_NAME]
                            [--text_column TEXT_COLUMN]
                            [--summary_column SUMMARY_COLUMN]
                            [--train_file TRAIN_FILE]
                            [--validation_file VALIDATION_FILE]
                            [--test_file TEST_FILE]
                            [--overwrite_cache [OVERWRITE_CACHE]]
                            [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                            [--max_source_length MAX_SOURCE_LENGTH]
                            [--max_target_length MAX_TARGET_LENGTH]
                            [--val_max_target_length VAL_MAX_TARGET_LENGTH]
                            [--no_pad_to_max_length]
                            [--pad_to_max_length [PAD_TO_MAX_LENGTH]]
                            [--max_train_samples MAX_TRAIN_SAMPLES]
                            [--max_eval_samples MAX_EVAL_SAMPLES]
                            [--max_predict_samples MAX_PREDICT_SAMPLES]
                            [--num_beams NUM_BEAMS]
                            [--no_ignore_pad_token_for_loss]
                            [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]
                            [--source_prefix SOURCE_PREFIX]
                            [--augmentor AUGMENTOR]
                            [--max_sentences MAX_SENTENCES]
                            [--mydebug [MYDEBUG]] --output_dir OUTPUT_DIR
                            [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                            [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                            [--do_predict [DO_PREDICT]]
                            [--evaluation_strategy {no,steps,epoch}]
                            [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                            [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                            [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                            [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                            [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                            [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                            [--learning_rate LEARNING_RATE]
                            [--weight_decay WEIGHT_DECAY]
                            [--adam_beta1 ADAM_BETA1]
                            [--adam_beta2 ADAM_BETA2]
                            [--adam_epsilon ADAM_EPSILON]
                            [--max_grad_norm MAX_GRAD_NORM]
                            [--num_train_epochs NUM_TRAIN_EPOCHS]
                            [--max_steps MAX_STEPS]
                            [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                            [--warmup_ratio WARMUP_RATIO]
                            [--warmup_steps WARMUP_STEPS]
                            [--log_level {debug,info,warning,error,critical,passive}]
                            [--log_level_replica {debug,info,warning,error,critical,passive}]
                            [--no_log_on_each_node]
                            [--log_on_each_node [LOG_ON_EACH_NODE]]
                            [--logging_dir LOGGING_DIR]
                            [--logging_strategy {no,steps,epoch}]
                            [--logging_first_step [LOGGING_FIRST_STEP]]
                            [--logging_steps LOGGING_STEPS]
                            [--save_strategy {no,steps,epoch}]
                            [--save_steps SAVE_STEPS]
                            [--save_total_limit SAVE_TOTAL_LIMIT]
                            [--save_on_each_node [SAVE_ON_EACH_NODE]]
                            [--no_cuda [NO_CUDA]] [--seed SEED]
                            [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]
                            [--fp16_backend {auto,amp,apex}]
                            [--fp16_full_eval [FP16_FULL_EVAL]]
                            [--local_rank LOCAL_RANK]
                            [--tpu_num_cores TPU_NUM_CORES]
                            [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                            [--debug DEBUG]
                            [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                            [--eval_steps EVAL_STEPS]
                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                            [--past_index PAST_INDEX] [--run_name RUN_NAME]
                            [--disable_tqdm DISABLE_TQDM]
                            [--no_remove_unused_columns]
                            [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                            [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                            [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                            [--greater_is_better GREATER_IS_BETTER]
                            [--ignore_data_skip [IGNORE_DATA_SKIP]]
                            [--sharded_ddp SHARDED_DDP]
                            [--deepspeed DEEPSPEED]
                            [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                            [--adafactor [ADAFACTOR]]
                            [--group_by_length [GROUP_BY_LENGTH]]
                            [--length_column_name LENGTH_COLUMN_NAME]
                            [--report_to REPORT_TO [REPORT_TO ...]]
                            [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                            [--no_dataloader_pin_memory]
                            [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                            [--no_skip_memory_metrics]
                            [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                            [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                            [--push_to_hub [PUSH_TO_HUB]]
                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                            [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                            [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                            [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                            [--mp_parameters MP_PARAMETERS]
                            [--sortish_sampler [SORTISH_SAMPLER]]
                            [--predict_with_generate [PREDICT_WITH_GENERATE]]
run_summarization.py: error: argument --predict_with_generate: Truthy value expected: got > but expected one of yes/no, true/false, t/f, y/n, 1/0 (case insensitive).
usage: run_summarization.py [-h] --model_name_or_path MODEL_NAME_OR_PATH
                            [--config_name CONFIG_NAME]
                            [--tokenizer_name TOKENIZER_NAME]
                            [--cache_dir CACHE_DIR] [--no_use_fast_tokenizer]
                            [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                            [--model_revision MODEL_REVISION]
                            [--use_auth_token [USE_AUTH_TOKEN]]
                            [--dropout DROPOUT] [--dataset_name DATASET_NAME]
                            [--dataset_config_name DATASET_CONFIG_NAME]
                            [--text_column TEXT_COLUMN]
                            [--summary_column SUMMARY_COLUMN]
                            [--train_file TRAIN_FILE]
                            [--validation_file VALIDATION_FILE]
                            [--test_file TEST_FILE]
                            [--overwrite_cache [OVERWRITE_CACHE]]
                            [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                            [--max_source_length MAX_SOURCE_LENGTH]
                            [--max_target_length MAX_TARGET_LENGTH]
                            [--val_max_target_length VAL_MAX_TARGET_LENGTH]
                            [--no_pad_to_max_length]
                            [--pad_to_max_length [PAD_TO_MAX_LENGTH]]
                            [--max_train_samples MAX_TRAIN_SAMPLES]
                            [--max_eval_samples MAX_EVAL_SAMPLES]
                            [--max_predict_samples MAX_PREDICT_SAMPLES]
                            [--num_beams NUM_BEAMS]
                            [--no_ignore_pad_token_for_loss]
                            [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]
                            [--source_prefix SOURCE_PREFIX]
                            [--augmentor AUGMENTOR]
                            [--max_sentences MAX_SENTENCES]
                            [--mydebug [MYDEBUG]] --output_dir OUTPUT_DIR
                            [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                            [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                            [--do_predict [DO_PREDICT]]
                            [--evaluation_strategy {no,steps,epoch}]
                            [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                            [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                            [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                            [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                            [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                            [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                            [--learning_rate LEARNING_RATE]
                            [--weight_decay WEIGHT_DECAY]
                            [--adam_beta1 ADAM_BETA1]
                            [--adam_beta2 ADAM_BETA2]
                            [--adam_epsilon ADAM_EPSILON]
                            [--max_grad_norm MAX_GRAD_NORM]
                            [--num_train_epochs NUM_TRAIN_EPOCHS]
                            [--max_steps MAX_STEPS]
                            [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                            [--warmup_ratio WARMUP_RATIO]
                            [--warmup_steps WARMUP_STEPS]
                            [--log_level {debug,info,warning,error,critical,passive}]
                            [--log_level_replica {debug,info,warning,error,critical,passive}]
                            [--no_log_on_each_node]
                            [--log_on_each_node [LOG_ON_EACH_NODE]]
                            [--logging_dir LOGGING_DIR]
                            [--logging_strategy {no,steps,epoch}]
                            [--logging_first_step [LOGGING_FIRST_STEP]]
                            [--logging_steps LOGGING_STEPS]
                            [--save_strategy {no,steps,epoch}]
                            [--save_steps SAVE_STEPS]
                            [--save_total_limit SAVE_TOTAL_LIMIT]
                            [--save_on_each_node [SAVE_ON_EACH_NODE]]
                            [--no_cuda [NO_CUDA]] [--seed SEED]
                            [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]
                            [--fp16_backend {auto,amp,apex}]
                            [--fp16_full_eval [FP16_FULL_EVAL]]
                            [--local_rank LOCAL_RANK]
                            [--tpu_num_cores TPU_NUM_CORES]
                            [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                            [--debug DEBUG]
                            [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                            [--eval_steps EVAL_STEPS]
                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                            [--past_index PAST_INDEX] [--run_name RUN_NAME]
                            [--disable_tqdm DISABLE_TQDM]
                            [--no_remove_unused_columns]
                            [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                            [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                            [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                            [--greater_is_better GREATER_IS_BETTER]
                            [--ignore_data_skip [IGNORE_DATA_SKIP]]
                            [--sharded_ddp SHARDED_DDP]
                            [--deepspeed DEEPSPEED]
                            [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                            [--adafactor [ADAFACTOR]]
                            [--group_by_length [GROUP_BY_LENGTH]]
                            [--length_column_name LENGTH_COLUMN_NAME]
                            [--report_to REPORT_TO [REPORT_TO ...]]
                            [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                            [--no_dataloader_pin_memory]
                            [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                            [--no_skip_memory_metrics]
                            [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                            [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                            [--push_to_hub [PUSH_TO_HUB]]
                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                            [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                            [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                            [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                            [--mp_parameters MP_PARAMETERS]
                            [--sortish_sampler [SORTISH_SAMPLER]]
                            [--predict_with_generate [PREDICT_WITH_GENERATE]]
run_summarization.py: error: argument --predict_with_generate: Truthy value expected: got > but expected one of yes/no, true/false, t/f, y/n, 1/0 (case insensitive).
usage: run_summarization.py [-h] --model_name_or_path MODEL_NAME_OR_PATH
                            [--config_name CONFIG_NAME]
                            [--tokenizer_name TOKENIZER_NAME]
                            [--cache_dir CACHE_DIR] [--no_use_fast_tokenizer]
                            [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                            [--model_revision MODEL_REVISION]
                            [--use_auth_token [USE_AUTH_TOKEN]]
                            [--dropout DROPOUT] [--dataset_name DATASET_NAME]
                            [--dataset_config_name DATASET_CONFIG_NAME]
                            [--text_column TEXT_COLUMN]
                            [--summary_column SUMMARY_COLUMN]
                            [--train_file TRAIN_FILE]
                            [--validation_file VALIDATION_FILE]
                            [--test_file TEST_FILE]
                            [--overwrite_cache [OVERWRITE_CACHE]]
                            [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                            [--max_source_length MAX_SOURCE_LENGTH]
                            [--max_target_length MAX_TARGET_LENGTH]
                            [--val_max_target_length VAL_MAX_TARGET_LENGTH]
                            [--no_pad_to_max_length]
                            [--pad_to_max_length [PAD_TO_MAX_LENGTH]]
                            [--max_train_samples MAX_TRAIN_SAMPLES]
                            [--max_eval_samples MAX_EVAL_SAMPLES]
                            [--max_predict_samples MAX_PREDICT_SAMPLES]
                            [--num_beams NUM_BEAMS]
                            [--no_ignore_pad_token_for_loss]
                            [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]
                            [--source_prefix SOURCE_PREFIX]
                            [--augmentor AUGMENTOR]
                            [--max_sentences MAX_SENTENCES]
                            [--mydebug [MYDEBUG]] --output_dir OUTPUT_DIR
                            [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                            [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                            [--do_predict [DO_PREDICT]]
                            [--evaluation_strategy {no,steps,epoch}]
                            [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                            [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                            [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                            [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                            [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                            [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                            [--learning_rate LEARNING_RATE]
                            [--weight_decay WEIGHT_DECAY]
                            [--adam_beta1 ADAM_BETA1]
                            [--adam_beta2 ADAM_BETA2]
                            [--adam_epsilon ADAM_EPSILON]
                            [--max_grad_norm MAX_GRAD_NORM]
                            [--num_train_epochs NUM_TRAIN_EPOCHS]
                            [--max_steps MAX_STEPS]
                            [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                            [--warmup_ratio WARMUP_RATIO]
                            [--warmup_steps WARMUP_STEPS]
                            [--log_level {debug,info,warning,error,critical,passive}]
                            [--log_level_replica {debug,info,warning,error,critical,passive}]
                            [--no_log_on_each_node]
                            [--log_on_each_node [LOG_ON_EACH_NODE]]
                            [--logging_dir LOGGING_DIR]
                            [--logging_strategy {no,steps,epoch}]
                            [--logging_first_step [LOGGING_FIRST_STEP]]
                            [--logging_steps LOGGING_STEPS]
                            [--save_strategy {no,steps,epoch}]
                            [--save_steps SAVE_STEPS]
                            [--save_total_limit SAVE_TOTAL_LIMIT]
                            [--save_on_each_node [SAVE_ON_EACH_NODE]]
                            [--no_cuda [NO_CUDA]] [--seed SEED]
                            [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]
                            [--fp16_backend {auto,amp,apex}]
                            [--fp16_full_eval [FP16_FULL_EVAL]]
                            [--local_rank LOCAL_RANK]
                            [--tpu_num_cores TPU_NUM_CORES]
                            [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                            [--debug DEBUG]
                            [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                            [--eval_steps EVAL_STEPS]
                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                            [--past_index PAST_INDEX] [--run_name RUN_NAME]
                            [--disable_tqdm DISABLE_TQDM]
                            [--no_remove_unused_columns]
                            [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                            [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                            [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                            [--greater_is_better GREATER_IS_BETTER]
                            [--ignore_data_skip [IGNORE_DATA_SKIP]]
                            [--sharded_ddp SHARDED_DDP]
                            [--deepspeed DEEPSPEED]
                            [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                            [--adafactor [ADAFACTOR]]
                            [--group_by_length [GROUP_BY_LENGTH]]
                            [--length_column_name LENGTH_COLUMN_NAME]
                            [--report_to REPORT_TO [REPORT_TO ...]]
                            [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                            [--no_dataloader_pin_memory]
                            [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                            [--no_skip_memory_metrics]
                            [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                            [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                            [--push_to_hub [PUSH_TO_HUB]]
                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                            [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                            [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                            [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                            [--mp_parameters MP_PARAMETERS]
                            [--sortish_sampler [SORTISH_SAMPLER]]
                            [--predict_with_generate [PREDICT_WITH_GENERATE]]
run_summarization.py: error: argument --predict_with_generate: Truthy value expected: got > but expected one of yes/no, true/false, t/f, y/n, 1/0 (case insensitive).
usage: run_summarization.py [-h] --model_name_or_path MODEL_NAME_OR_PATH
                            [--config_name CONFIG_NAME]
                            [--tokenizer_name TOKENIZER_NAME]
                            [--cache_dir CACHE_DIR] [--no_use_fast_tokenizer]
                            [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                            [--model_revision MODEL_REVISION]
                            [--use_auth_token [USE_AUTH_TOKEN]]
                            [--dropout DROPOUT] [--dataset_name DATASET_NAME]
                            [--dataset_config_name DATASET_CONFIG_NAME]
                            [--text_column TEXT_COLUMN]
                            [--summary_column SUMMARY_COLUMN]
                            [--train_file TRAIN_FILE]
                            [--validation_file VALIDATION_FILE]
                            [--test_file TEST_FILE]
                            [--overwrite_cache [OVERWRITE_CACHE]]
                            [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                            [--max_source_length MAX_SOURCE_LENGTH]
                            [--max_target_length MAX_TARGET_LENGTH]
                            [--val_max_target_length VAL_MAX_TARGET_LENGTH]
                            [--no_pad_to_max_length]
                            [--pad_to_max_length [PAD_TO_MAX_LENGTH]]
                            [--max_train_samples MAX_TRAIN_SAMPLES]
                            [--max_eval_samples MAX_EVAL_SAMPLES]
                            [--max_predict_samples MAX_PREDICT_SAMPLES]
                            [--num_beams NUM_BEAMS]
                            [--no_ignore_pad_token_for_loss]
                            [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]
                            [--source_prefix SOURCE_PREFIX]
                            [--augmentor AUGMENTOR]
                            [--max_sentences MAX_SENTENCES]
                            [--mydebug [MYDEBUG]] --output_dir OUTPUT_DIR
                            [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                            [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                            [--do_predict [DO_PREDICT]]
                            [--evaluation_strategy {no,steps,epoch}]
                            [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                            [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                            [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                            [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                            [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                            [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                            [--learning_rate LEARNING_RATE]
                            [--weight_decay WEIGHT_DECAY]
                            [--adam_beta1 ADAM_BETA1]
                            [--adam_beta2 ADAM_BETA2]
                            [--adam_epsilon ADAM_EPSILON]
                            [--max_grad_norm MAX_GRAD_NORM]
                            [--num_train_epochs NUM_TRAIN_EPOCHS]
                            [--max_steps MAX_STEPS]
                            [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                            [--warmup_ratio WARMUP_RATIO]
                            [--warmup_steps WARMUP_STEPS]
                            [--log_level {debug,info,warning,error,critical,passive}]
                            [--log_level_replica {debug,info,warning,error,critical,passive}]
                            [--no_log_on_each_node]
                            [--log_on_each_node [LOG_ON_EACH_NODE]]
                            [--logging_dir LOGGING_DIR]
                            [--logging_strategy {no,steps,epoch}]
                            [--logging_first_step [LOGGING_FIRST_STEP]]
                            [--logging_steps LOGGING_STEPS]
                            [--save_strategy {no,steps,epoch}]
                            [--save_steps SAVE_STEPS]
                            [--save_total_limit SAVE_TOTAL_LIMIT]
                            [--save_on_each_node [SAVE_ON_EACH_NODE]]
                            [--no_cuda [NO_CUDA]] [--seed SEED]
                            [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]
                            [--fp16_backend {auto,amp,apex}]
                            [--fp16_full_eval [FP16_FULL_EVAL]]
                            [--local_rank LOCAL_RANK]
                            [--tpu_num_cores TPU_NUM_CORES]
                            [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                            [--debug DEBUG]
                            [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                            [--eval_steps EVAL_STEPS]
                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                            [--past_index PAST_INDEX] [--run_name RUN_NAME]
                            [--disable_tqdm DISABLE_TQDM]
                            [--no_remove_unused_columns]
                            [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                            [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                            [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                            [--greater_is_better GREATER_IS_BETTER]
                            [--ignore_data_skip [IGNORE_DATA_SKIP]]
                            [--sharded_ddp SHARDED_DDP]
                            [--deepspeed DEEPSPEED]
                            [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                            [--adafactor [ADAFACTOR]]
                            [--group_by_length [GROUP_BY_LENGTH]]
                            [--length_column_name LENGTH_COLUMN_NAME]
                            [--report_to REPORT_TO [REPORT_TO ...]]
                            [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                            [--no_dataloader_pin_memory]
                            [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                            [--no_skip_memory_metrics]
                            [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                            [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                            [--push_to_hub [PUSH_TO_HUB]]
                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                            [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                            [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                            [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                            [--mp_parameters MP_PARAMETERS]
                            [--sortish_sampler [SORTISH_SAMPLER]]
                            [--predict_with_generate [PREDICT_WITH_GENERATE]]
run_summarization.py: error: argument --predict_with_generate: Truthy value expected: got > but expected one of yes/no, true/false, t/f, y/n, 1/0 (case insensitive).
usage: run_summarization.py [-h] --model_name_or_path MODEL_NAME_OR_PATH
                            [--config_name CONFIG_NAME]
                            [--tokenizer_name TOKENIZER_NAME]
                            [--cache_dir CACHE_DIR] [--no_use_fast_tokenizer]
                            [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                            [--model_revision MODEL_REVISION]
                            [--use_auth_token [USE_AUTH_TOKEN]]
                            [--dropout DROPOUT] [--dataset_name DATASET_NAME]
                            [--dataset_config_name DATASET_CONFIG_NAME]
                            [--text_column TEXT_COLUMN]
                            [--summary_column SUMMARY_COLUMN]
                            [--train_file TRAIN_FILE]
                            [--validation_file VALIDATION_FILE]
                            [--test_file TEST_FILE]
                            [--overwrite_cache [OVERWRITE_CACHE]]
                            [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                            [--max_source_length MAX_SOURCE_LENGTH]
                            [--max_target_length MAX_TARGET_LENGTH]
                            [--val_max_target_length VAL_MAX_TARGET_LENGTH]
                            [--no_pad_to_max_length]
                            [--pad_to_max_length [PAD_TO_MAX_LENGTH]]
                            [--max_train_samples MAX_TRAIN_SAMPLES]
                            [--max_eval_samples MAX_EVAL_SAMPLES]
                            [--max_predict_samples MAX_PREDICT_SAMPLES]
                            [--num_beams NUM_BEAMS]
                            [--no_ignore_pad_token_for_loss]
                            [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]
                            [--source_prefix SOURCE_PREFIX]
                            [--augmentor AUGMENTOR]
                            [--max_sentences MAX_SENTENCES]
                            [--mydebug [MYDEBUG]] --output_dir OUTPUT_DIR
                            [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                            [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                            [--do_predict [DO_PREDICT]]
                            [--evaluation_strategy {no,steps,epoch}]
                            [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                            [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                            [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                            [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                            [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                            [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                            [--learning_rate LEARNING_RATE]
                            [--weight_decay WEIGHT_DECAY]
                            [--adam_beta1 ADAM_BETA1]
                            [--adam_beta2 ADAM_BETA2]
                            [--adam_epsilon ADAM_EPSILON]
                            [--max_grad_norm MAX_GRAD_NORM]
                            [--num_train_epochs NUM_TRAIN_EPOCHS]
                            [--max_steps MAX_STEPS]
                            [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                            [--warmup_ratio WARMUP_RATIO]
                            [--warmup_steps WARMUP_STEPS]
                            [--log_level {debug,info,warning,error,critical,passive}]
                            [--log_level_replica {debug,info,warning,error,critical,passive}]
                            [--no_log_on_each_node]
                            [--log_on_each_node [LOG_ON_EACH_NODE]]
                            [--logging_dir LOGGING_DIR]
                            [--logging_strategy {no,steps,epoch}]
                            [--logging_first_step [LOGGING_FIRST_STEP]]
                            [--logging_steps LOGGING_STEPS]
                            [--save_strategy {no,steps,epoch}]
                            [--save_steps SAVE_STEPS]
                            [--save_total_limit SAVE_TOTAL_LIMIT]
                            [--save_on_each_node [SAVE_ON_EACH_NODE]]
                            [--no_cuda [NO_CUDA]] [--seed SEED]
                            [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]
                            [--fp16_backend {auto,amp,apex}]
                            [--fp16_full_eval [FP16_FULL_EVAL]]
                            [--local_rank LOCAL_RANK]
                            [--tpu_num_cores TPU_NUM_CORES]
                            [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                            [--debug DEBUG]
                            [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                            [--eval_steps EVAL_STEPS]
                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                            [--past_index PAST_INDEX] [--run_name RUN_NAME]
                            [--disable_tqdm DISABLE_TQDM]
                            [--no_remove_unused_columns]
                            [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                            [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                            [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                            [--greater_is_better GREATER_IS_BETTER]
                            [--ignore_data_skip [IGNORE_DATA_SKIP]]
                            [--sharded_ddp SHARDED_DDP]
                            [--deepspeed DEEPSPEED]
                            [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                            [--adafactor [ADAFACTOR]]
                            [--group_by_length [GROUP_BY_LENGTH]]
                            [--length_column_name LENGTH_COLUMN_NAME]
                            [--report_to REPORT_TO [REPORT_TO ...]]
                            [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                            [--no_dataloader_pin_memory]
                            [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                            [--no_skip_memory_metrics]
                            [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                            [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                            [--push_to_hub [PUSH_TO_HUB]]
                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                            [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                            [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                            [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                            [--mp_parameters MP_PARAMETERS]
                            [--sortish_sampler [SORTISH_SAMPLER]]
                            [--predict_with_generate [PREDICT_WITH_GENERATE]]
run_summarization.py: error: argument --predict_with_generate: Truthy value expected: got > but expected one of yes/no, true/false, t/f, y/n, 1/0 (case insensitive).
usage: run_summarization.py [-h] --model_name_or_path MODEL_NAME_OR_PATH
                            [--config_name CONFIG_NAME]
                            [--tokenizer_name TOKENIZER_NAME]
                            [--cache_dir CACHE_DIR] [--no_use_fast_tokenizer]
                            [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                            [--model_revision MODEL_REVISION]
                            [--use_auth_token [USE_AUTH_TOKEN]]
                            [--dropout DROPOUT] [--dataset_name DATASET_NAME]
                            [--dataset_config_name DATASET_CONFIG_NAME]
                            [--text_column TEXT_COLUMN]
                            [--summary_column SUMMARY_COLUMN]
                            [--train_file TRAIN_FILE]
                            [--validation_file VALIDATION_FILE]
                            [--test_file TEST_FILE]
                            [--overwrite_cache [OVERWRITE_CACHE]]
                            [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                            [--max_source_length MAX_SOURCE_LENGTH]
                            [--max_target_length MAX_TARGET_LENGTH]
                            [--val_max_target_length VAL_MAX_TARGET_LENGTH]
                            [--no_pad_to_max_length]
                            [--pad_to_max_length [PAD_TO_MAX_LENGTH]]
                            [--max_train_samples MAX_TRAIN_SAMPLES]
                            [--max_eval_samples MAX_EVAL_SAMPLES]
                            [--max_predict_samples MAX_PREDICT_SAMPLES]
                            [--num_beams NUM_BEAMS]
                            [--no_ignore_pad_token_for_loss]
                            [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]
                            [--source_prefix SOURCE_PREFIX]
                            [--augmentor AUGMENTOR]
                            [--max_sentences MAX_SENTENCES]
                            [--mydebug [MYDEBUG]] --output_dir OUTPUT_DIR
                            [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                            [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                            [--do_predict [DO_PREDICT]]
                            [--evaluation_strategy {no,steps,epoch}]
                            [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                            [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                            [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                            [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                            [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                            [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                            [--learning_rate LEARNING_RATE]
                            [--weight_decay WEIGHT_DECAY]
                            [--adam_beta1 ADAM_BETA1]
                            [--adam_beta2 ADAM_BETA2]
                            [--adam_epsilon ADAM_EPSILON]
                            [--max_grad_norm MAX_GRAD_NORM]
                            [--num_train_epochs NUM_TRAIN_EPOCHS]
                            [--max_steps MAX_STEPS]
                            [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                            [--warmup_ratio WARMUP_RATIO]
                            [--warmup_steps WARMUP_STEPS]
                            [--log_level {debug,info,warning,error,critical,passive}]
                            [--log_level_replica {debug,info,warning,error,critical,passive}]
                            [--no_log_on_each_node]
                            [--log_on_each_node [LOG_ON_EACH_NODE]]
                            [--logging_dir LOGGING_DIR]
                            [--logging_strategy {no,steps,epoch}]
                            [--logging_first_step [LOGGING_FIRST_STEP]]
                            [--logging_steps LOGGING_STEPS]
                            [--save_strategy {no,steps,epoch}]
                            [--save_steps SAVE_STEPS]
                            [--save_total_limit SAVE_TOTAL_LIMIT]
                            [--save_on_each_node [SAVE_ON_EACH_NODE]]
                            [--no_cuda [NO_CUDA]] [--seed SEED]
                            [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]
                            [--fp16_backend {auto,amp,apex}]
                            [--fp16_full_eval [FP16_FULL_EVAL]]
                            [--local_rank LOCAL_RANK]
                            [--tpu_num_cores TPU_NUM_CORES]
                            [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                            [--debug DEBUG]
                            [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                            [--eval_steps EVAL_STEPS]
                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                            [--past_index PAST_INDEX] [--run_name RUN_NAME]
                            [--disable_tqdm DISABLE_TQDM]
                            [--no_remove_unused_columns]
                            [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                            [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                            [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                            [--greater_is_better GREATER_IS_BETTER]
                            [--ignore_data_skip [IGNORE_DATA_SKIP]]
                            [--sharded_ddp SHARDED_DDP]
                            [--deepspeed DEEPSPEED]
                            [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                            [--adafactor [ADAFACTOR]]
                            [--group_by_length [GROUP_BY_LENGTH]]
                            [--length_column_name LENGTH_COLUMN_NAME]
                            [--report_to REPORT_TO [REPORT_TO ...]]
                            [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                            [--no_dataloader_pin_memory]
                            [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                            [--no_skip_memory_metrics]
                            [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                            [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                            [--push_to_hub [PUSH_TO_HUB]]
                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                            [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                            [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                            [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                            [--mp_parameters MP_PARAMETERS]
                            [--sortish_sampler [SORTISH_SAMPLER]]
                            [--predict_with_generate [PREDICT_WITH_GENERATE]]
run_summarization.py: error: argument --predict_with_generate: Truthy value expected: got > but expected one of yes/no, true/false, t/f, y/n, 1/0 (case insensitive).
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 22549) of binary: /home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/bin/python
ERROR:torch.distributed.elastic.agent.server.local_elastic_agent:[default] Worker group failed
INFO:torch.distributed.elastic.agent.server.api:[default] Worker group FAILED. 3/3 attempts left; will restart worker group
INFO:torch.distributed.elastic.agent.server.api:[default] Stopping worker group
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=1
  master_addr=127.0.0.1
  master_port=29500
  group_rank=0
  group_world_size=1
  local_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
  role_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
  global_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
  role_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]
  global_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_5mjucvs5/none_6nek00ej/attempt_1/0/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_5mjucvs5/none_6nek00ej/attempt_1/1/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /tmp/torchelastic_5mjucvs5/none_6nek00ej/attempt_1/2/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /tmp/torchelastic_5mjucvs5/none_6nek00ej/attempt_1/3/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker4 reply file to: /tmp/torchelastic_5mjucvs5/none_6nek00ej/attempt_1/4/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker5 reply file to: /tmp/torchelastic_5mjucvs5/none_6nek00ej/attempt_1/5/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker6 reply file to: /tmp/torchelastic_5mjucvs5/none_6nek00ej/attempt_1/6/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker7 reply file to: /tmp/torchelastic_5mjucvs5/none_6nek00ej/attempt_1/7/error.json
Traceback (most recent call last):
Traceback (most recent call last):
  File "run_summarization.py", line 34, in <module>
Traceback (most recent call last):
  File "run_summarization.py", line 34, in <module>
Traceback (most recent call last):
  File "run_summarization.py", line 34, in <module>
Traceback (most recent call last):
  File "run_summarization.py", line 34, in <module>
Traceback (most recent call last):
  File "run_summarization.py", line 34, in <module>
Traceback (most recent call last):
  File "run_summarization.py", line 34, in <module>
  File "run_summarization.py", line 34, in <module>
    from transformers import (    
from transformers import (
  File "<frozen importlib._bootstrap>", line 1039, in _handle_fromlist
  File "<frozen importlib._bootstrap>", line 1039, in _handle_fromlist
    from transformers import (
  File "<frozen importlib._bootstrap>", line 1039, in _handle_fromlist
    from transformers import (
      File "<frozen importlib._bootstrap>", line 1039, in _handle_fromlist
from transformers import (  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 1985, in __getattr__
    
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 1985, in __getattr__
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 1985, in __getattr__
from transformers import (  File "<frozen importlib._bootstrap>", line 1039, in _handle_fromlist

  File "<frozen importlib._bootstrap>", line 1039, in _handle_fromlist
    from transformers import (
  File "<frozen importlib._bootstrap>", line 1039, in _handle_fromlist
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 1985, in __getattr__
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 1985, in __getattr__
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 1985, in __getattr__
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 1985, in __getattr__
    value = getattr(module, name)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 1984, in __getattr__
    value = getattr(module, name)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 1984, in __getattr__
    value = getattr(module, name)    
value = getattr(module, name)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 1984, in __getattr__
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 1984, in __getattr__
    value = getattr(module, name)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 1984, in __getattr__
    value = getattr(module, name)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 1984, in __getattr__
    value = getattr(module, name)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 1984, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 1993, in _get_module
    module = self._get_module(self._class_to_module[name])
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 1993, in _get_module
    module = self._get_module(self._class_to_module[name])
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 1993, in _get_module
    module = self._get_module(self._class_to_module[name])
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 1993, in _get_module
    module = self._get_module(self._class_to_module[name])
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 1993, in _get_module
    module = self._get_module(self._class_to_module[name])
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 1993, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/importlib/__init__.py", line 127, in import_module
    module = self._get_module(self._class_to_module[name])
      File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 1993, in _get_module
return importlib.import_module("." + module_name, self.__name__)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py", line 87, in <module>
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/models/auto/modeling_auto.py", line 24, in <module>
    return _bootstrap._gcd_import(name[level:], package, level)
      File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py", line 69, in <module>
return _bootstrap._gcd_import(name[level:], package, level)
      File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py", line 61, in <module>
return _bootstrap._gcd_import(name[level:], package, level)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/models/auto/modeling_auto.py", line 84, in <module>
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py", line 87, in <module>
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/models/auto/modeling_auto.py", line 24, in <module>
    from ..albert.modeling_albert import (
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/models/albert/modeling_albert.py", line 623, in <module>
    from ..albert.modeling_albert import (
    from ..canine.modeling_canine import (  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/models/albert/modeling_albert.py", line 985, in <module>

  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/models/canine/modeling_canine.py", line 1450, in <module>
            from ..prophetnet.configuration_prophetnet import PROPHETNET_PRETRAINED_CONFIG_ARCHIVE_MAP, ProphetNetConfig    from ..xlm_prophetnet.configuration_xlm_prophetnet import (from ..marian.configuration_marian import MarianConfigfrom ..xlm_prophetnet.configuration_xlm_prophetnet import (



  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/models/xlm_prophetnet/__init__.py", line 27, in <module>
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/models/xlm_prophetnet/__init__.py", line 27, in <module>
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 914, in _find_spec
  File "<frozen importlib._bootstrap>", line 914, in _find_spec
  File "<frozen importlib._bootstrap_external>", line 1407, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1407, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1379, in _get_spec
  File "<frozen importlib._bootstrap_external>", line 1379, in _get_spec
  File "<frozen importlib._bootstrap_external>", line 1510, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1510, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1553, in _fill_cache
  File "<frozen importlib._bootstrap_external>", line 1553, in _fill_cache
KeyboardInterrupt
KeyboardInterrupt
        from .modeling_xlm_prophetnet import (from .modeling_xlm_prophetnet import (

  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py", line 18, in <module>
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py", line 18, in <module>
    from ..prophetnet.modeling_prophetnet import (
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/models/prophetnet/modeling_prophetnet.py", line 35, in <module>
    from ..prophetnet.modeling_prophetnet import (
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/models/prophetnet/modeling_prophetnet.py", line 35, in <module>
    class CanineForTokenClassification(CaninePreTrainedModel):
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/models/canine/modeling_canine.py", line 1468, in CanineForTokenClassification
    class AlbertForSequenceClassification(AlbertPreTrainedModel):
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/models/albert/modeling_albert.py", line 1004, in AlbertForSequenceClassification
    def forward(
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 1175, in docstring_decorator
    def forward(
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 1175, in docstring_decorator
    output_doc = _prepare_output_docstrings(output_type, config_class) if output_type is not None else ""
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 752, in _prepare_output_docstrings
    output_doc = _prepare_output_docstrings(output_type, config_class) if output_type is not None else ""
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 752, in _prepare_output_docstrings
    docstrings = _convert_output_args_doc(docstrings)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 721, in _convert_output_args_doc
    docstrings = _convert_output_args_doc(docstrings)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 734, in _convert_output_args_doc
    if _get_indent(line) == indent:
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 709, in _get_indent
    blocks[i] = re.sub(r":\s*\n\s*(\S)", r" -- \1", blocks[i])
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/re.py", line 210, in sub
    search = re.search(r"^(\s*)\S", t)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/re.py", line 201, in search
        from ...modeling_outputs import BaseModelOutputfrom ...modeling_outputs import BaseModelOutput

  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/modeling_outputs.py", line 50, in <module>
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/modeling_outputs.py", line 153, in <module>
    class BaseModelOutputWithPooling(ModelOutput):
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/dataclasses.py", line 1019, in dataclass
    class BaseModelOutputWithPoolingAndCrossAttentions(ModelOutput):
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/modeling_outputs.py", line 196, in BaseModelOutputWithPoolingAndCrossAttentions
    attentions: Optional[Tuple[torch.FloatTensor]] = None
KeyboardInterrupt
        return _compile(pattern, flags).search(string)return _compile(pattern, flags).sub(repl, string, count)

KeyboardInterrupt  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/re.py", line 325, in _subx

    def _subx(pattern, template):
KeyboardInterrupt
    return wrap(cls)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/dataclasses.py", line 1011, in wrap
    return _process_class(cls, init, repr, eq, order, unsafe_hash, frozen)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/dataclasses.py", line 951, in _process_class
    _cmp_fn('__eq__', '==',
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/dataclasses.py", line 579, in _cmp_fn
    return _create_fn(name,
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/dataclasses.py", line 398, in _create_fn
    exec(txt, globals, ns)
  File "<string>", line 1, in <module>
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/launch.py", line 173, in <module>
    main()
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/launch.py", line 169, in main
    run(args)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/run.py", line 621, in run
    elastic_launch(
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 116, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 238, in launch_agent
    result = agent.run()
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/elastic/metrics/api.py", line 125, in wrapper
    result = f(*args, **kwargs)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 700, in run
    result = self._invoke_run(role)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 828, in _invoke_run
    time.sleep(monitor_interval)
KeyboardInterrupt
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/launch.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  logger.warn(
The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run
WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.
 Please read local_rank from `os.environ('LOCAL_RANK')` instead.
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : run_summarization.py
  min_nodes        : 1
  max_nodes        : 1
  nproc_per_node   : 8
  run_id           : none
  rdzv_backend     : static
  rdzv_endpoint    : 127.0.0.1:29500
  rdzv_configs     : {'rank': 0, 'timeout': 900}
  max_restarts     : 3
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_j7wifvgi/none_e9de0txo
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:52: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=127.0.0.1
  master_port=29500
  group_rank=0
  group_world_size=1
  local_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
  role_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
  global_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
  role_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]
  global_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_j7wifvgi/none_e9de0txo/attempt_0/0/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_j7wifvgi/none_e9de0txo/attempt_0/1/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /tmp/torchelastic_j7wifvgi/none_e9de0txo/attempt_0/2/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /tmp/torchelastic_j7wifvgi/none_e9de0txo/attempt_0/3/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker4 reply file to: /tmp/torchelastic_j7wifvgi/none_e9de0txo/attempt_0/4/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker5 reply file to: /tmp/torchelastic_j7wifvgi/none_e9de0txo/attempt_0/5/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker6 reply file to: /tmp/torchelastic_j7wifvgi/none_e9de0txo/attempt_0/6/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker7 reply file to: /tmp/torchelastic_j7wifvgi/none_e9de0txo/attempt_0/7/error.json
Traceback (most recent call last):
  File "run_summarization.py", line 32, in <module>
Traceback (most recent call last):
  File "run_summarization.py", line 32, in <module>
Traceback (most recent call last):
  File "run_summarization.py", line 32, in <module>
    import transformers
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/__init__.py", line 43, in <module>
    import transformers
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/__init__.py", line 43, in <module>
    import transformers
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/__init__.py", line 43, in <module>
    from . import dependency_versions_check
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/dependency_versions_check.py", line 36, in <module>
    from . import dependency_versions_check
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/dependency_versions_check.py", line 36, in <module>
    from . import dependency_versions_check
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/dependency_versions_check.py", line 36, in <module>
    from .file_utils import is_tokenizers_available
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 51, in <module>
    from .file_utils import is_tokenizers_available
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 51, in <module>
    from huggingface_hub import HfApi, HfFolder, Repository
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/huggingface_hub/__init__.py", line 34, in <module>
    from .file_utils import is_tokenizers_available
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 51, in <module>
    from .hub_mixin import ModelHubMixin
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/huggingface_hub/hub_mixin.py", line 16, in <module>
        from huggingface_hub import HfApi, HfFolder, Repositoryfrom huggingface_hub import HfApi, HfFolder, Repository

  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/huggingface_hub/__init__.py", line 34, in <module>
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/huggingface_hub/__init__.py", line 34, in <module>
    import torch
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/__init__.py", line 588, in <module>
        from .hub_mixin import ModelHubMixinfrom .hub_mixin import ModelHubMixin

  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/huggingface_hub/hub_mixin.py", line 16, in <module>
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/huggingface_hub/hub_mixin.py", line 16, in <module>
    import torch
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/__init__.py", line 587, in <module>
    import torch
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/__init__.py", line 587, in <module>
    from ._tensor_str import set_printoptions
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/_tensor_str.py", line 2, in <module>
    from .serialization import save, load
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/serialization.py", line 15, in <module>
    from .serialization import save, load
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/serialization.py", line 15, in <module>
    from torch.types import Storage
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/types.py", line 22, in <module>
    from torch.types import Storage
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 844, in exec_module
  File "<frozen importlib._bootstrap_external>", line 939, in get_code
  File "<frozen importlib._bootstrap_external>", line 1037, in get_data
KeyboardInterrupt
Traceback (most recent call last):
  File "run_summarization.py", line 32, in <module>
    import transformers
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/__init__.py", line 43, in <module>
    from . import dependency_versions_check
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/dependency_versions_check.py", line 36, in <module>
    from .file_utils import is_tokenizers_available
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 51, in <module>
    from huggingface_hub import HfApi, HfFolder, Repository
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/huggingface_hub/__init__.py", line 34, in <module>
    from .hub_mixin import ModelHubMixin
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/huggingface_hub/hub_mixin.py", line 16, in <module>
    import torch
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/__init__.py", line 197, in <module>
    from torch._C import *  # noqa: F403
RuntimeError: KeyboardInterrupt: 
    _size = Union[torch.Size, List[_int], Tuple[_int, ...]]
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/typing.py", line 258, in inner
    import torch
  File "<frozen importlib._bootstrap>", line 202, in _lock_unlock_module
  File "<frozen importlib._bootstrap>", line 90, in acquire
KeyboardInterrupt
    return cached(*args, **kwds)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/typing.py", line 720, in __hash__
    def __hash__(self):
KeyboardInterrupt
Traceback (most recent call last):
  File "run_summarization.py", line 32, in <module>
    import transformers
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/__init__.py", line 43, in <module>
    from . import dependency_versions_check
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/dependency_versions_check.py", line 36, in <module>
    from .file_utils import is_tokenizers_available
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 51, in <module>
    from huggingface_hub import HfApi, HfFolder, Repository
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/huggingface_hub/__init__.py", line 34, in <module>
    from .hub_mixin import ModelHubMixin
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/huggingface_hub/hub_mixin.py", line 16, in <module>
    import torch
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/__init__.py", line 197, in <module>
    from torch._C import *  # noqa: F403
RuntimeError: KeyboardInterrupt: 
Traceback (most recent call last):
Traceback (most recent call last):
  File "run_summarization.py", line 32, in <module>
  File "run_summarization.py", line 32, in <module>
    import transformers
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/__init__.py", line 43, in <module>
    import transformers
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/__init__.py", line 43, in <module>
    from . import dependency_versions_check
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/dependency_versions_check.py", line 36, in <module>
    from . import dependency_versions_check
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/dependency_versions_check.py", line 36, in <module>
    from .file_utils import is_tokenizers_available
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 51, in <module>
    from .file_utils import is_tokenizers_available
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/transformers/file_utils.py", line 51, in <module>
    from huggingface_hub import HfApi, HfFolder, Repository
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/huggingface_hub/__init__.py", line 34, in <module>
    from huggingface_hub import HfApi, HfFolder, Repository
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/huggingface_hub/__init__.py", line 34, in <module>
    from .hub_mixin import ModelHubMixin
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/huggingface_hub/hub_mixin.py", line 16, in <module>
    from .hub_mixin import ModelHubMixin
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/huggingface_hub/hub_mixin.py", line 16, in <module>
        import torchimport torch

  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/__init__.py", line 197, in <module>
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/__init__.py", line 197, in <module>
    from torch._C import *  # noqa: F403
RuntimeError: KeyboardInterrupt: 
    from torch._C import *  # noqa: F403
RuntimeError: KeyboardInterrupt: 
Traceback (most recent call last):
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/launch.py", line 173, in <module>
    main()
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/launch.py", line 169, in main
    run(args)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/run.py", line 621, in run
    elastic_launch(
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 116, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 238, in launch_agent
    result = agent.run()
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/elastic/metrics/api.py", line 125, in wrapper
    result = f(*args, **kwargs)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 700, in run
    result = self._invoke_run(role)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 828, in _invoke_run
    time.sleep(monitor_interval)
KeyboardInterrupt
/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/launch.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  logger.warn(
The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run
WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.
 Please read local_rank from `os.environ('LOCAL_RANK')` instead.
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : run_summarization.py
  min_nodes        : 1
  max_nodes        : 1
  nproc_per_node   : 8
  run_id           : none
  rdzv_backend     : static
  rdzv_endpoint    : 127.0.0.1:29500
  rdzv_configs     : {'rank': 0, 'timeout': 900}
  max_restarts     : 3
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_901jnvvh/none_fyx3niyj
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:52: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=127.0.0.1
  master_port=29500
  group_rank=0
  group_world_size=1
  local_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
  role_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
  global_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
  role_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]
  global_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_901jnvvh/none_fyx3niyj/attempt_0/0/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_901jnvvh/none_fyx3niyj/attempt_0/1/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /tmp/torchelastic_901jnvvh/none_fyx3niyj/attempt_0/2/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /tmp/torchelastic_901jnvvh/none_fyx3niyj/attempt_0/3/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker4 reply file to: /tmp/torchelastic_901jnvvh/none_fyx3niyj/attempt_0/4/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker5 reply file to: /tmp/torchelastic_901jnvvh/none_fyx3niyj/attempt_0/5/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker6 reply file to: /tmp/torchelastic_901jnvvh/none_fyx3niyj/attempt_0/6/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker7 reply file to: /tmp/torchelastic_901jnvvh/none_fyx3niyj/attempt_0/7/error.json
usage: run_summarization.py [-h] --model_name_or_path MODEL_NAME_OR_PATH
                            [--config_name CONFIG_NAME]
                            [--tokenizer_name TOKENIZER_NAME]
                            [--cache_dir CACHE_DIR] [--no_use_fast_tokenizer]
                            [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                            [--model_revision MODEL_REVISION]
                            [--use_auth_token [USE_AUTH_TOKEN]]
                            [--dropout DROPOUT] [--dataset_name DATASET_NAME]
                            [--dataset_config_name DATASET_CONFIG_NAME]
                            [--text_column TEXT_COLUMN]
                            [--summary_column SUMMARY_COLUMN]
                            [--train_file TRAIN_FILE]
                            [--validation_file VALIDATION_FILE]
                            [--test_file TEST_FILE]
                            [--overwrite_cache [OVERWRITE_CACHE]]
                            [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                            [--max_source_length MAX_SOURCE_LENGTH]
                            [--max_target_length MAX_TARGET_LENGTH]
                            [--val_max_target_length VAL_MAX_TARGET_LENGTH]
                            [--no_pad_to_max_length]
                            [--pad_to_max_length [PAD_TO_MAX_LENGTH]]
                            [--max_train_samples MAX_TRAIN_SAMPLES]
                            [--max_eval_samples MAX_EVAL_SAMPLES]
                            [--max_predict_samples MAX_PREDICT_SAMPLES]
                            [--num_beams NUM_BEAMS]
                            [--no_ignore_pad_token_for_loss]
                            [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]
                            [--source_prefix SOURCE_PREFIX]
                            [--augmentor AUGMENTOR]
                            [--max_sentences MAX_SENTENCES]
                            [--mydebug [MYDEBUG]] --output_dir OUTPUT_DIR
                            [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                            [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                            [--do_predict [DO_PREDICT]]
                            [--evaluation_strategy {no,steps,epoch}]
                            [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                            [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                            [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                            [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                            [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                            [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                            [--learning_rate LEARNING_RATE]
                            [--weight_decay WEIGHT_DECAY]
                            [--adam_beta1 ADAM_BETA1]
                            [--adam_beta2 ADAM_BETA2]
                            [--adam_epsilon ADAM_EPSILON]
                            [--max_grad_norm MAX_GRAD_NORM]
                            [--num_train_epochs NUM_TRAIN_EPOCHS]
                            [--max_steps MAX_STEPS]
                            [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                            [--warmup_ratio WARMUP_RATIO]
                            [--warmup_steps WARMUP_STEPS]
                            [--log_level {debug,info,warning,error,critical,passive}]
                            [--log_level_replica {debug,info,warning,error,critical,passive}]
                            [--no_log_on_each_node]
                            [--log_on_each_node [LOG_ON_EACH_NODE]]
                            [--logging_dir LOGGING_DIR]
                            [--logging_strategy {no,steps,epoch}]
                            [--logging_first_step [LOGGING_FIRST_STEP]]
                            [--logging_steps LOGGING_STEPS]
                            [--save_strategy {no,steps,epoch}]
                            [--save_steps SAVE_STEPS]
                            [--save_total_limit SAVE_TOTAL_LIMIT]
                            [--save_on_each_node [SAVE_ON_EACH_NODE]]
                            [--no_cuda [NO_CUDA]] [--seed SEED]
                            [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]
                            [--fp16_backend {auto,amp,apex}]
                            [--fp16_full_eval [FP16_FULL_EVAL]]
                            [--local_rank LOCAL_RANK]
                            [--tpu_num_cores TPU_NUM_CORES]
                            [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                            [--debug DEBUG]
                            [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                            [--eval_steps EVAL_STEPS]
                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                            [--past_index PAST_INDEX] [--run_name RUN_NAME]
                            [--disable_tqdm DISABLE_TQDM]
                            [--no_remove_unused_columns]
                            [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                            [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                            [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                            [--greater_is_better GREATER_IS_BETTER]
                            [--ignore_data_skip [IGNORE_DATA_SKIP]]
                            [--sharded_ddp SHARDED_DDP]
                            [--deepspeed DEEPSPEED]
                            [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                            [--adafactor [ADAFACTOR]]
                            [--group_by_length [GROUP_BY_LENGTH]]
                            [--length_column_name LENGTH_COLUMN_NAME]
                            [--report_to REPORT_TO [REPORT_TO ...]]
                            [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                            [--no_dataloader_pin_memory]
                            [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                            [--no_skip_memory_metrics]
                            [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                            [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                            [--push_to_hub [PUSH_TO_HUB]]
                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                            [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                            [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                            [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                            [--mp_parameters MP_PARAMETERS]
                            [--sortish_sampler [SORTISH_SAMPLER]]
                            [--predict_with_generate [PREDICT_WITH_GENERATE]]
run_summarization.py: error: argument --predict_with_generate: Truthy value expected: got > but expected one of yes/no, true/false, t/f, y/n, 1/0 (case insensitive).
usage: run_summarization.py [-h] --model_name_or_path MODEL_NAME_OR_PATH
                            [--config_name CONFIG_NAME]
                            [--tokenizer_name TOKENIZER_NAME]
                            [--cache_dir CACHE_DIR] [--no_use_fast_tokenizer]
                            [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                            [--model_revision MODEL_REVISION]
                            [--use_auth_token [USE_AUTH_TOKEN]]
                            [--dropout DROPOUT] [--dataset_name DATASET_NAME]
                            [--dataset_config_name DATASET_CONFIG_NAME]
                            [--text_column TEXT_COLUMN]
                            [--summary_column SUMMARY_COLUMN]
                            [--train_file TRAIN_FILE]
                            [--validation_file VALIDATION_FILE]
                            [--test_file TEST_FILE]
                            [--overwrite_cache [OVERWRITE_CACHE]]
                            [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                            [--max_source_length MAX_SOURCE_LENGTH]
                            [--max_target_length MAX_TARGET_LENGTH]
                            [--val_max_target_length VAL_MAX_TARGET_LENGTH]
                            [--no_pad_to_max_length]
                            [--pad_to_max_length [PAD_TO_MAX_LENGTH]]
                            [--max_train_samples MAX_TRAIN_SAMPLES]
                            [--max_eval_samples MAX_EVAL_SAMPLES]
                            [--max_predict_samples MAX_PREDICT_SAMPLES]
                            [--num_beams NUM_BEAMS]
                            [--no_ignore_pad_token_for_loss]
                            [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]
                            [--source_prefix SOURCE_PREFIX]
                            [--augmentor AUGMENTOR]
                            [--max_sentences MAX_SENTENCES]
                            [--mydebug [MYDEBUG]] --output_dir OUTPUT_DIR
                            [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                            [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                            [--do_predict [DO_PREDICT]]
                            [--evaluation_strategy {no,steps,epoch}]
                            [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                            [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                            [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                            [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                            [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                            [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                            [--learning_rate LEARNING_RATE]
                            [--weight_decay WEIGHT_DECAY]
                            [--adam_beta1 ADAM_BETA1]
                            [--adam_beta2 ADAM_BETA2]
                            [--adam_epsilon ADAM_EPSILON]
                            [--max_grad_norm MAX_GRAD_NORM]
                            [--num_train_epochs NUM_TRAIN_EPOCHS]
                            [--max_steps MAX_STEPS]
                            [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                            [--warmup_ratio WARMUP_RATIO]
                            [--warmup_steps WARMUP_STEPS]
                            [--log_level {debug,info,warning,error,critical,passive}]
                            [--log_level_replica {debug,info,warning,error,critical,passive}]
                            [--no_log_on_each_node]
                            [--log_on_each_node [LOG_ON_EACH_NODE]]
                            [--logging_dir LOGGING_DIR]
                            [--logging_strategy {no,steps,epoch}]
                            [--logging_first_step [LOGGING_FIRST_STEP]]
                            [--logging_steps LOGGING_STEPS]
                            [--save_strategy {no,steps,epoch}]
                            [--save_steps SAVE_STEPS]
                            [--save_total_limit SAVE_TOTAL_LIMIT]
                            [--save_on_each_node [SAVE_ON_EACH_NODE]]
                            [--no_cuda [NO_CUDA]] [--seed SEED]
                            [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]
                            [--fp16_backend {auto,amp,apex}]
                            [--fp16_full_eval [FP16_FULL_EVAL]]
                            [--local_rank LOCAL_RANK]
                            [--tpu_num_cores TPU_NUM_CORES]
                            [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                            [--debug DEBUG]
                            [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                            [--eval_steps EVAL_STEPS]
                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                            [--past_index PAST_INDEX] [--run_name RUN_NAME]
                            [--disable_tqdm DISABLE_TQDM]
                            [--no_remove_unused_columns]
                            [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                            [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                            [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                            [--greater_is_better GREATER_IS_BETTER]
                            [--ignore_data_skip [IGNORE_DATA_SKIP]]
                            [--sharded_ddp SHARDED_DDP]
                            [--deepspeed DEEPSPEED]
                            [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                            [--adafactor [ADAFACTOR]]
                            [--group_by_length [GROUP_BY_LENGTH]]
                            [--length_column_name LENGTH_COLUMN_NAME]
                            [--report_to REPORT_TO [REPORT_TO ...]]
                            [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                            [--no_dataloader_pin_memory]
                            [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                            [--no_skip_memory_metrics]
                            [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                            [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                            [--push_to_hub [PUSH_TO_HUB]]
                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                            [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                            [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                            [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                            [--mp_parameters MP_PARAMETERS]
                            [--sortish_sampler [SORTISH_SAMPLER]]
                            [--predict_with_generate [PREDICT_WITH_GENERATE]]
run_summarization.py: error: argument --predict_with_generate: Truthy value expected: got > but expected one of yes/no, true/false, t/f, y/n, 1/0 (case insensitive).
usage: run_summarization.py [-h] --model_name_or_path MODEL_NAME_OR_PATH
                            [--config_name CONFIG_NAME]
                            [--tokenizer_name TOKENIZER_NAME]
                            [--cache_dir CACHE_DIR] [--no_use_fast_tokenizer]
                            [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                            [--model_revision MODEL_REVISION]
                            [--use_auth_token [USE_AUTH_TOKEN]]
                            [--dropout DROPOUT] [--dataset_name DATASET_NAME]
                            [--dataset_config_name DATASET_CONFIG_NAME]
                            [--text_column TEXT_COLUMN]
                            [--summary_column SUMMARY_COLUMN]
                            [--train_file TRAIN_FILE]
                            [--validation_file VALIDATION_FILE]
                            [--test_file TEST_FILE]
                            [--overwrite_cache [OVERWRITE_CACHE]]
                            [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                            [--max_source_length MAX_SOURCE_LENGTH]
                            [--max_target_length MAX_TARGET_LENGTH]
                            [--val_max_target_length VAL_MAX_TARGET_LENGTH]
                            [--no_pad_to_max_length]
                            [--pad_to_max_length [PAD_TO_MAX_LENGTH]]
                            [--max_train_samples MAX_TRAIN_SAMPLES]
                            [--max_eval_samples MAX_EVAL_SAMPLES]
                            [--max_predict_samples MAX_PREDICT_SAMPLES]
                            [--num_beams NUM_BEAMS]
                            [--no_ignore_pad_token_for_loss]
                            [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]
                            [--source_prefix SOURCE_PREFIX]
                            [--augmentor AUGMENTOR]
                            [--max_sentences MAX_SENTENCES]
                            [--mydebug [MYDEBUG]] --output_dir OUTPUT_DIR
                            [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                            [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                            [--do_predict [DO_PREDICT]]
                            [--evaluation_strategy {no,steps,epoch}]
                            [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                            [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                            [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                            [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                            [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                            [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                            [--learning_rate LEARNING_RATE]
                            [--weight_decay WEIGHT_DECAY]
                            [--adam_beta1 ADAM_BETA1]
                            [--adam_beta2 ADAM_BETA2]
                            [--adam_epsilon ADAM_EPSILON]
                            [--max_grad_norm MAX_GRAD_NORM]
                            [--num_train_epochs NUM_TRAIN_EPOCHS]
                            [--max_steps MAX_STEPS]
                            [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                            [--warmup_ratio WARMUP_RATIO]
                            [--warmup_steps WARMUP_STEPS]
                            [--log_level {debug,info,warning,error,critical,passive}]
                            [--log_level_replica {debug,info,warning,error,critical,passive}]
                            [--no_log_on_each_node]
                            [--log_on_each_node [LOG_ON_EACH_NODE]]
                            [--logging_dir LOGGING_DIR]
                            [--logging_strategy {no,steps,epoch}]
                            [--logging_first_step [LOGGING_FIRST_STEP]]
                            [--logging_steps LOGGING_STEPS]
                            [--save_strategy {no,steps,epoch}]
                            [--save_steps SAVE_STEPS]
                            [--save_total_limit SAVE_TOTAL_LIMIT]
                            [--save_on_each_node [SAVE_ON_EACH_NODE]]
                            [--no_cuda [NO_CUDA]] [--seed SEED]
                            [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]
                            [--fp16_backend {auto,amp,apex}]
                            [--fp16_full_eval [FP16_FULL_EVAL]]
                            [--local_rank LOCAL_RANK]
                            [--tpu_num_cores TPU_NUM_CORES]
                            [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                            [--debug DEBUG]
                            [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                            [--eval_steps EVAL_STEPS]
                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                            [--past_index PAST_INDEX] [--run_name RUN_NAME]
                            [--disable_tqdm DISABLE_TQDM]
                            [--no_remove_unused_columns]
                            [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                            [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                            [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                            [--greater_is_better GREATER_IS_BETTER]
                            [--ignore_data_skip [IGNORE_DATA_SKIP]]
                            [--sharded_ddp SHARDED_DDP]
                            [--deepspeed DEEPSPEED]
                            [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                            [--adafactor [ADAFACTOR]]
                            [--group_by_length [GROUP_BY_LENGTH]]
                            [--length_column_name LENGTH_COLUMN_NAME]
                            [--report_to REPORT_TO [REPORT_TO ...]]
                            [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                            [--no_dataloader_pin_memory]
                            [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                            [--no_skip_memory_metrics]
                            [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                            [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                            [--push_to_hub [PUSH_TO_HUB]]
                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                            [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                            [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                            [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                            [--mp_parameters MP_PARAMETERS]
                            [--sortish_sampler [SORTISH_SAMPLER]]
                            [--predict_with_generate [PREDICT_WITH_GENERATE]]
run_summarization.py: error: argument --predict_with_generate: Truthy value expected: got > but expected one of yes/no, true/false, t/f, y/n, 1/0 (case insensitive).
usage: run_summarization.py [-h] --model_name_or_path MODEL_NAME_OR_PATH
                            [--config_name CONFIG_NAME]
                            [--tokenizer_name TOKENIZER_NAME]
                            [--cache_dir CACHE_DIR] [--no_use_fast_tokenizer]
                            [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                            [--model_revision MODEL_REVISION]
                            [--use_auth_token [USE_AUTH_TOKEN]]
                            [--dropout DROPOUT] [--dataset_name DATASET_NAME]
                            [--dataset_config_name DATASET_CONFIG_NAME]
                            [--text_column TEXT_COLUMN]
                            [--summary_column SUMMARY_COLUMN]
                            [--train_file TRAIN_FILE]
                            [--validation_file VALIDATION_FILE]
                            [--test_file TEST_FILE]
                            [--overwrite_cache [OVERWRITE_CACHE]]
                            [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                            [--max_source_length MAX_SOURCE_LENGTH]
                            [--max_target_length MAX_TARGET_LENGTH]
                            [--val_max_target_length VAL_MAX_TARGET_LENGTH]
                            [--no_pad_to_max_length]
                            [--pad_to_max_length [PAD_TO_MAX_LENGTH]]
                            [--max_train_samples MAX_TRAIN_SAMPLES]
                            [--max_eval_samples MAX_EVAL_SAMPLES]
                            [--max_predict_samples MAX_PREDICT_SAMPLES]
                            [--num_beams NUM_BEAMS]
                            [--no_ignore_pad_token_for_loss]
                            [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]
                            [--source_prefix SOURCE_PREFIX]
                            [--augmentor AUGMENTOR]
                            [--max_sentences MAX_SENTENCES]
                            [--mydebug [MYDEBUG]] --output_dir OUTPUT_DIR
                            [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                            [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                            [--do_predict [DO_PREDICT]]
                            [--evaluation_strategy {no,steps,epoch}]
                            [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                            [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                            [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                            [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                            [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                            [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                            [--learning_rate LEARNING_RATE]
                            [--weight_decay WEIGHT_DECAY]
                            [--adam_beta1 ADAM_BETA1]
                            [--adam_beta2 ADAM_BETA2]
                            [--adam_epsilon ADAM_EPSILON]
                            [--max_grad_norm MAX_GRAD_NORM]
                            [--num_train_epochs NUM_TRAIN_EPOCHS]
                            [--max_steps MAX_STEPS]
                            [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                            [--warmup_ratio WARMUP_RATIO]
                            [--warmup_steps WARMUP_STEPS]
                            [--log_level {debug,info,warning,error,critical,passive}]
                            [--log_level_replica {debug,info,warning,error,critical,passive}]
                            [--no_log_on_each_node]
                            [--log_on_each_node [LOG_ON_EACH_NODE]]
                            [--logging_dir LOGGING_DIR]
                            [--logging_strategy {no,steps,epoch}]
                            [--logging_first_step [LOGGING_FIRST_STEP]]
                            [--logging_steps LOGGING_STEPS]
                            [--save_strategy {no,steps,epoch}]
                            [--save_steps SAVE_STEPS]
                            [--save_total_limit SAVE_TOTAL_LIMIT]
                            [--save_on_each_node [SAVE_ON_EACH_NODE]]
                            [--no_cuda [NO_CUDA]] [--seed SEED]
                            [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]
                            [--fp16_backend {auto,amp,apex}]
                            [--fp16_full_eval [FP16_FULL_EVAL]]
                            [--local_rank LOCAL_RANK]
                            [--tpu_num_cores TPU_NUM_CORES]
                            [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                            [--debug DEBUG]
                            [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                            [--eval_steps EVAL_STEPS]
                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                            [--past_index PAST_INDEX] [--run_name RUN_NAME]
                            [--disable_tqdm DISABLE_TQDM]
                            [--no_remove_unused_columns]
                            [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                            [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                            [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                            [--greater_is_better GREATER_IS_BETTER]
                            [--ignore_data_skip [IGNORE_DATA_SKIP]]
                            [--sharded_ddp SHARDED_DDP]
                            [--deepspeed DEEPSPEED]
                            [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                            [--adafactor [ADAFACTOR]]
                            [--group_by_length [GROUP_BY_LENGTH]]
                            [--length_column_name LENGTH_COLUMN_NAME]
                            [--report_to REPORT_TO [REPORT_TO ...]]
                            [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                            [--no_dataloader_pin_memory]
                            [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                            [--no_skip_memory_metrics]
                            [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                            [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                            [--push_to_hub [PUSH_TO_HUB]]
                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                            [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                            [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                            [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                            [--mp_parameters MP_PARAMETERS]
                            [--sortish_sampler [SORTISH_SAMPLER]]
                            [--predict_with_generate [PREDICT_WITH_GENERATE]]
run_summarization.py: error: argument --predict_with_generate: Truthy value expected: got > but expected one of yes/no, true/false, t/f, y/n, 1/0 (case insensitive).
usage: run_summarization.py [-h] --model_name_or_path MODEL_NAME_OR_PATH
                            [--config_name CONFIG_NAME]
                            [--tokenizer_name TOKENIZER_NAME]
                            [--cache_dir CACHE_DIR] [--no_use_fast_tokenizer]
                            [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                            [--model_revision MODEL_REVISION]
                            [--use_auth_token [USE_AUTH_TOKEN]]
                            [--dropout DROPOUT] [--dataset_name DATASET_NAME]
                            [--dataset_config_name DATASET_CONFIG_NAME]
                            [--text_column TEXT_COLUMN]
                            [--summary_column SUMMARY_COLUMN]
                            [--train_file TRAIN_FILE]
                            [--validation_file VALIDATION_FILE]
                            [--test_file TEST_FILE]
                            [--overwrite_cache [OVERWRITE_CACHE]]
                            [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                            [--max_source_length MAX_SOURCE_LENGTH]
                            [--max_target_length MAX_TARGET_LENGTH]
                            [--val_max_target_length VAL_MAX_TARGET_LENGTH]
                            [--no_pad_to_max_length]
                            [--pad_to_max_length [PAD_TO_MAX_LENGTH]]
                            [--max_train_samples MAX_TRAIN_SAMPLES]
                            [--max_eval_samples MAX_EVAL_SAMPLES]
                            [--max_predict_samples MAX_PREDICT_SAMPLES]
                            [--num_beams NUM_BEAMS]
                            [--no_ignore_pad_token_for_loss]
                            [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]
                            [--source_prefix SOURCE_PREFIX]
                            [--augmentor AUGMENTOR]
                            [--max_sentences MAX_SENTENCES]
                            [--mydebug [MYDEBUG]] --output_dir OUTPUT_DIR
                            [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                            [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                            [--do_predict [DO_PREDICT]]
                            [--evaluation_strategy {no,steps,epoch}]
                            [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                            [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                            [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                            [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                            [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                            [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                            [--learning_rate LEARNING_RATE]
                            [--weight_decay WEIGHT_DECAY]
                            [--adam_beta1 ADAM_BETA1]
                            [--adam_beta2 ADAM_BETA2]
                            [--adam_epsilon ADAM_EPSILON]
                            [--max_grad_norm MAX_GRAD_NORM]
                            [--num_train_epochs NUM_TRAIN_EPOCHS]
                            [--max_steps MAX_STEPS]
                            [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                            [--warmup_ratio WARMUP_RATIO]
                            [--warmup_steps WARMUP_STEPS]
                            [--log_level {debug,info,warning,error,critical,passive}]
                            [--log_level_replica {debug,info,warning,error,critical,passive}]
                            [--no_log_on_each_node]
                            [--log_on_each_node [LOG_ON_EACH_NODE]]
                            [--logging_dir LOGGING_DIR]
                            [--logging_strategy {no,steps,epoch}]
                            [--logging_first_step [LOGGING_FIRST_STEP]]
                            [--logging_steps LOGGING_STEPS]
                            [--save_strategy {no,steps,epoch}]
                            [--save_steps SAVE_STEPS]
                            [--save_total_limit SAVE_TOTAL_LIMIT]
                            [--save_on_each_node [SAVE_ON_EACH_NODE]]
                            [--no_cuda [NO_CUDA]] [--seed SEED]
                            [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]
                            [--fp16_backend {auto,amp,apex}]
                            [--fp16_full_eval [FP16_FULL_EVAL]]
                            [--local_rank LOCAL_RANK]
                            [--tpu_num_cores TPU_NUM_CORES]
                            [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                            [--debug DEBUG]
                            [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                            [--eval_steps EVAL_STEPS]
                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                            [--past_index PAST_INDEX] [--run_name RUN_NAME]
                            [--disable_tqdm DISABLE_TQDM]
                            [--no_remove_unused_columns]
                            [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                            [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                            [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                            [--greater_is_better GREATER_IS_BETTER]
                            [--ignore_data_skip [IGNORE_DATA_SKIP]]
                            [--sharded_ddp SHARDED_DDP]
                            [--deepspeed DEEPSPEED]
                            [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                            [--adafactor [ADAFACTOR]]
                            [--group_by_length [GROUP_BY_LENGTH]]
                            [--length_column_name LENGTH_COLUMN_NAME]
                            [--report_to REPORT_TO [REPORT_TO ...]]
                            [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                            [--no_dataloader_pin_memory]
                            [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                            [--no_skip_memory_metrics]
                            [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                            [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                            [--push_to_hub [PUSH_TO_HUB]]
                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                            [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                            [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                            [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                            [--mp_parameters MP_PARAMETERS]
                            [--sortish_sampler [SORTISH_SAMPLER]]
                            [--predict_with_generate [PREDICT_WITH_GENERATE]]
run_summarization.py: error: argument --predict_with_generate: Truthy value expected: got > but expected one of yes/no, true/false, t/f, y/n, 1/0 (case insensitive).
usage: run_summarization.py [-h] --model_name_or_path MODEL_NAME_OR_PATH
                            [--config_name CONFIG_NAME]
                            [--tokenizer_name TOKENIZER_NAME]
                            [--cache_dir CACHE_DIR] [--no_use_fast_tokenizer]
                            [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                            [--model_revision MODEL_REVISION]
                            [--use_auth_token [USE_AUTH_TOKEN]]
                            [--dropout DROPOUT] [--dataset_name DATASET_NAME]
                            [--dataset_config_name DATASET_CONFIG_NAME]
                            [--text_column TEXT_COLUMN]
                            [--summary_column SUMMARY_COLUMN]
                            [--train_file TRAIN_FILE]
                            [--validation_file VALIDATION_FILE]
                            [--test_file TEST_FILE]
                            [--overwrite_cache [OVERWRITE_CACHE]]
                            [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                            [--max_source_length MAX_SOURCE_LENGTH]
                            [--max_target_length MAX_TARGET_LENGTH]
                            [--val_max_target_length VAL_MAX_TARGET_LENGTH]
                            [--no_pad_to_max_length]
                            [--pad_to_max_length [PAD_TO_MAX_LENGTH]]
                            [--max_train_samples MAX_TRAIN_SAMPLES]
                            [--max_eval_samples MAX_EVAL_SAMPLES]
                            [--max_predict_samples MAX_PREDICT_SAMPLES]
                            [--num_beams NUM_BEAMS]
                            [--no_ignore_pad_token_for_loss]
                            [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]
                            [--source_prefix SOURCE_PREFIX]
                            [--augmentor AUGMENTOR]
                            [--max_sentences MAX_SENTENCES]
                            [--mydebug [MYDEBUG]] --output_dir OUTPUT_DIR
                            [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                            [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                            [--do_predict [DO_PREDICT]]
                            [--evaluation_strategy {no,steps,epoch}]
                            [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                            [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                            [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                            [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                            [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                            [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                            [--learning_rate LEARNING_RATE]
                            [--weight_decay WEIGHT_DECAY]
                            [--adam_beta1 ADAM_BETA1]
                            [--adam_beta2 ADAM_BETA2]
                            [--adam_epsilon ADAM_EPSILON]
                            [--max_grad_norm MAX_GRAD_NORM]
                            [--num_train_epochs NUM_TRAIN_EPOCHS]
                            [--max_steps MAX_STEPS]
                            [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                            [--warmup_ratio WARMUP_RATIO]
                            [--warmup_steps WARMUP_STEPS]
                            [--log_level {debug,info,warning,error,critical,passive}]
                            [--log_level_replica {debug,info,warning,error,critical,passive}]
                            [--no_log_on_each_node]
                            [--log_on_each_node [LOG_ON_EACH_NODE]]
                            [--logging_dir LOGGING_DIR]
                            [--logging_strategy {no,steps,epoch}]
                            [--logging_first_step [LOGGING_FIRST_STEP]]
                            [--logging_steps LOGGING_STEPS]
                            [--save_strategy {no,steps,epoch}]
                            [--save_steps SAVE_STEPS]
                            [--save_total_limit SAVE_TOTAL_LIMIT]
                            [--save_on_each_node [SAVE_ON_EACH_NODE]]
                            [--no_cuda [NO_CUDA]] [--seed SEED]
                            [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]
                            [--fp16_backend {auto,amp,apex}]
                            [--fp16_full_eval [FP16_FULL_EVAL]]
                            [--local_rank LOCAL_RANK]
                            [--tpu_num_cores TPU_NUM_CORES]
                            [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                            [--debug DEBUG]
                            [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                            [--eval_steps EVAL_STEPS]
                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                            [--past_index PAST_INDEX] [--run_name RUN_NAME]
                            [--disable_tqdm DISABLE_TQDM]
                            [--no_remove_unused_columns]
                            [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                            [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                            [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                            [--greater_is_better GREATER_IS_BETTER]
                            [--ignore_data_skip [IGNORE_DATA_SKIP]]
                            [--sharded_ddp SHARDED_DDP]
                            [--deepspeed DEEPSPEED]
                            [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                            [--adafactor [ADAFACTOR]]
                            [--group_by_length [GROUP_BY_LENGTH]]
                            [--length_column_name LENGTH_COLUMN_NAME]
                            [--report_to REPORT_TO [REPORT_TO ...]]
                            [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                            [--no_dataloader_pin_memory]
                            [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                            [--no_skip_memory_metrics]
                            [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                            [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                            [--push_to_hub [PUSH_TO_HUB]]
                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                            [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                            [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                            [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                            [--mp_parameters MP_PARAMETERS]
                            [--sortish_sampler [SORTISH_SAMPLER]]
                            [--predict_with_generate [PREDICT_WITH_GENERATE]]
run_summarization.py: error: argument --predict_with_generate: Truthy value expected: got > but expected one of yes/no, true/false, t/f, y/n, 1/0 (case insensitive).
usage: run_summarization.py [-h] --model_name_or_path MODEL_NAME_OR_PATH
                            [--config_name CONFIG_NAME]
                            [--tokenizer_name TOKENIZER_NAME]
                            [--cache_dir CACHE_DIR] [--no_use_fast_tokenizer]
                            [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                            [--model_revision MODEL_REVISION]
                            [--use_auth_token [USE_AUTH_TOKEN]]
                            [--dropout DROPOUT] [--dataset_name DATASET_NAME]
                            [--dataset_config_name DATASET_CONFIG_NAME]
                            [--text_column TEXT_COLUMN]
                            [--summary_column SUMMARY_COLUMN]
                            [--train_file TRAIN_FILE]
                            [--validation_file VALIDATION_FILE]
                            [--test_file TEST_FILE]
                            [--overwrite_cache [OVERWRITE_CACHE]]
                            [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                            [--max_source_length MAX_SOURCE_LENGTH]
                            [--max_target_length MAX_TARGET_LENGTH]
                            [--val_max_target_length VAL_MAX_TARGET_LENGTH]
                            [--no_pad_to_max_length]
                            [--pad_to_max_length [PAD_TO_MAX_LENGTH]]
                            [--max_train_samples MAX_TRAIN_SAMPLES]
                            [--max_eval_samples MAX_EVAL_SAMPLES]
                            [--max_predict_samples MAX_PREDICT_SAMPLES]
                            [--num_beams NUM_BEAMS]
                            [--no_ignore_pad_token_for_loss]
                            [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]
                            [--source_prefix SOURCE_PREFIX]
                            [--augmentor AUGMENTOR]
                            [--max_sentences MAX_SENTENCES]
                            [--mydebug [MYDEBUG]] --output_dir OUTPUT_DIR
                            [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                            [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                            [--do_predict [DO_PREDICT]]
                            [--evaluation_strategy {no,steps,epoch}]
                            [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                            [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                            [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                            [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                            [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                            [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                            [--learning_rate LEARNING_RATE]
                            [--weight_decay WEIGHT_DECAY]
                            [--adam_beta1 ADAM_BETA1]
                            [--adam_beta2 ADAM_BETA2]
                            [--adam_epsilon ADAM_EPSILON]
                            [--max_grad_norm MAX_GRAD_NORM]
                            [--num_train_epochs NUM_TRAIN_EPOCHS]
                            [--max_steps MAX_STEPS]
                            [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                            [--warmup_ratio WARMUP_RATIO]
                            [--warmup_steps WARMUP_STEPS]
                            [--log_level {debug,info,warning,error,critical,passive}]
                            [--log_level_replica {debug,info,warning,error,critical,passive}]
                            [--no_log_on_each_node]
                            [--log_on_each_node [LOG_ON_EACH_NODE]]
                            [--logging_dir LOGGING_DIR]
                            [--logging_strategy {no,steps,epoch}]
                            [--logging_first_step [LOGGING_FIRST_STEP]]
                            [--logging_steps LOGGING_STEPS]
                            [--save_strategy {no,steps,epoch}]
                            [--save_steps SAVE_STEPS]
                            [--save_total_limit SAVE_TOTAL_LIMIT]
                            [--save_on_each_node [SAVE_ON_EACH_NODE]]
                            [--no_cuda [NO_CUDA]] [--seed SEED]
                            [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]
                            [--fp16_backend {auto,amp,apex}]
                            [--fp16_full_eval [FP16_FULL_EVAL]]
                            [--local_rank LOCAL_RANK]
                            [--tpu_num_cores TPU_NUM_CORES]
                            [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                            [--debug DEBUG]
                            [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                            [--eval_steps EVAL_STEPS]
                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                            [--past_index PAST_INDEX] [--run_name RUN_NAME]
                            [--disable_tqdm DISABLE_TQDM]
                            [--no_remove_unused_columns]
                            [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                            [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                            [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                            [--greater_is_better GREATER_IS_BETTER]
                            [--ignore_data_skip [IGNORE_DATA_SKIP]]
                            [--sharded_ddp SHARDED_DDP]
                            [--deepspeed DEEPSPEED]
                            [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                            [--adafactor [ADAFACTOR]]
                            [--group_by_length [GROUP_BY_LENGTH]]
                            [--length_column_name LENGTH_COLUMN_NAME]
                            [--report_to REPORT_TO [REPORT_TO ...]]
                            [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                            [--no_dataloader_pin_memory]
                            [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                            [--no_skip_memory_metrics]
                            [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                            [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                            [--push_to_hub [PUSH_TO_HUB]]
                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                            [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                            [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                            [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                            [--mp_parameters MP_PARAMETERS]
                            [--sortish_sampler [SORTISH_SAMPLER]]
                            [--predict_with_generate [PREDICT_WITH_GENERATE]]
run_summarization.py: error: argument --predict_with_generate: Truthy value expected: got > but expected one of yes/no, true/false, t/f, y/n, 1/0 (case insensitive).
usage: run_summarization.py [-h] --model_name_or_path MODEL_NAME_OR_PATH
                            [--config_name CONFIG_NAME]
                            [--tokenizer_name TOKENIZER_NAME]
                            [--cache_dir CACHE_DIR] [--no_use_fast_tokenizer]
                            [--use_fast_tokenizer [USE_FAST_TOKENIZER]]
                            [--model_revision MODEL_REVISION]
                            [--use_auth_token [USE_AUTH_TOKEN]]
                            [--dropout DROPOUT] [--dataset_name DATASET_NAME]
                            [--dataset_config_name DATASET_CONFIG_NAME]
                            [--text_column TEXT_COLUMN]
                            [--summary_column SUMMARY_COLUMN]
                            [--train_file TRAIN_FILE]
                            [--validation_file VALIDATION_FILE]
                            [--test_file TEST_FILE]
                            [--overwrite_cache [OVERWRITE_CACHE]]
                            [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]
                            [--max_source_length MAX_SOURCE_LENGTH]
                            [--max_target_length MAX_TARGET_LENGTH]
                            [--val_max_target_length VAL_MAX_TARGET_LENGTH]
                            [--no_pad_to_max_length]
                            [--pad_to_max_length [PAD_TO_MAX_LENGTH]]
                            [--max_train_samples MAX_TRAIN_SAMPLES]
                            [--max_eval_samples MAX_EVAL_SAMPLES]
                            [--max_predict_samples MAX_PREDICT_SAMPLES]
                            [--num_beams NUM_BEAMS]
                            [--no_ignore_pad_token_for_loss]
                            [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]
                            [--source_prefix SOURCE_PREFIX]
                            [--augmentor AUGMENTOR]
                            [--max_sentences MAX_SENTENCES]
                            [--mydebug [MYDEBUG]] --output_dir OUTPUT_DIR
                            [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]
                            [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]
                            [--do_predict [DO_PREDICT]]
                            [--evaluation_strategy {no,steps,epoch}]
                            [--prediction_loss_only [PREDICTION_LOSS_ONLY]]
                            [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]
                            [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]
                            [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]
                            [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]
                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                            [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]
                            [--learning_rate LEARNING_RATE]
                            [--weight_decay WEIGHT_DECAY]
                            [--adam_beta1 ADAM_BETA1]
                            [--adam_beta2 ADAM_BETA2]
                            [--adam_epsilon ADAM_EPSILON]
                            [--max_grad_norm MAX_GRAD_NORM]
                            [--num_train_epochs NUM_TRAIN_EPOCHS]
                            [--max_steps MAX_STEPS]
                            [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]
                            [--warmup_ratio WARMUP_RATIO]
                            [--warmup_steps WARMUP_STEPS]
                            [--log_level {debug,info,warning,error,critical,passive}]
                            [--log_level_replica {debug,info,warning,error,critical,passive}]
                            [--no_log_on_each_node]
                            [--log_on_each_node [LOG_ON_EACH_NODE]]
                            [--logging_dir LOGGING_DIR]
                            [--logging_strategy {no,steps,epoch}]
                            [--logging_first_step [LOGGING_FIRST_STEP]]
                            [--logging_steps LOGGING_STEPS]
                            [--save_strategy {no,steps,epoch}]
                            [--save_steps SAVE_STEPS]
                            [--save_total_limit SAVE_TOTAL_LIMIT]
                            [--save_on_each_node [SAVE_ON_EACH_NODE]]
                            [--no_cuda [NO_CUDA]] [--seed SEED]
                            [--fp16 [FP16]] [--fp16_opt_level FP16_OPT_LEVEL]
                            [--fp16_backend {auto,amp,apex}]
                            [--fp16_full_eval [FP16_FULL_EVAL]]
                            [--local_rank LOCAL_RANK]
                            [--tpu_num_cores TPU_NUM_CORES]
                            [--tpu_metrics_debug [TPU_METRICS_DEBUG]]
                            [--debug DEBUG]
                            [--dataloader_drop_last [DATALOADER_DROP_LAST]]
                            [--eval_steps EVAL_STEPS]
                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]
                            [--past_index PAST_INDEX] [--run_name RUN_NAME]
                            [--disable_tqdm DISABLE_TQDM]
                            [--no_remove_unused_columns]
                            [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]
                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]
                            [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]
                            [--metric_for_best_model METRIC_FOR_BEST_MODEL]
                            [--greater_is_better GREATER_IS_BETTER]
                            [--ignore_data_skip [IGNORE_DATA_SKIP]]
                            [--sharded_ddp SHARDED_DDP]
                            [--deepspeed DEEPSPEED]
                            [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]
                            [--adafactor [ADAFACTOR]]
                            [--group_by_length [GROUP_BY_LENGTH]]
                            [--length_column_name LENGTH_COLUMN_NAME]
                            [--report_to REPORT_TO [REPORT_TO ...]]
                            [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]
                            [--no_dataloader_pin_memory]
                            [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]
                            [--no_skip_memory_metrics]
                            [--skip_memory_metrics [SKIP_MEMORY_METRICS]]
                            [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]
                            [--push_to_hub [PUSH_TO_HUB]]
                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]
                            [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]
                            [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]
                            [--push_to_hub_token PUSH_TO_HUB_TOKEN]
                            [--mp_parameters MP_PARAMETERS]
                            [--sortish_sampler [SORTISH_SAMPLER]]
                            [--predict_with_generate [PREDICT_WITH_GENERATE]]
run_summarization.py: error: argument --predict_with_generate: Truthy value expected: got > but expected one of yes/no, true/false, t/f, y/n, 1/0 (case insensitive).
Traceback (most recent call last):
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/launch.py", line 173, in <module>
    main()
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/launch.py", line 169, in main
    run(args)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/run.py", line 621, in run
    elastic_launch(
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 116, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 238, in launch_agent
    result = agent.run()
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/elastic/metrics/api.py", line 125, in wrapper
    result = f(*args, **kwargs)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 700, in run
    result = self._invoke_run(role)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 828, in _invoke_run
    time.sleep(monitor_interval)
KeyboardInterrupt
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Traceback (most recent call last):
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/runpy.py", line 185, in _run_module_as_main
    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/runpy.py", line 111, in _get_module_details
    __import__(pkg_name)
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/__init__.py", line 684, in <module>
    import torch.nn.quantizable
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/nn/quantizable/__init__.py", line 1, in <module>
    from .modules import *  # noqa: F403
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/nn/quantizable/modules/__init__.py", line 1, in <module>
    from .activation import MultiheadAttention
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/nn/quantizable/modules/activation.py", line 4, in <module>
    import torch.nn.quantized as nnq
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/nn/quantized/__init__.py", line 1, in <module>
    from .modules import *  # noqa: F403
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/nn/quantized/modules/__init__.py", line 8, in <module>
    from .conv import _ConvNd, Conv1d, Conv2d, Conv3d
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/nn/quantized/modules/conv.py", line 10, in <module>
    import torch.nn.intrinsic.qat as nniqat
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/nn/intrinsic/qat/__init__.py", line 1, in <module>
    from .modules import *  # noqa: F403
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/nn/intrinsic/qat/modules/__init__.py", line 1, in <module>
    from .linear_relu import LinearReLU
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/nn/intrinsic/qat/modules/linear_relu.py", line 1, in <module>
    import torch.nn.qat as nnqat
  File "/home/gamir/DER-Roei/eladb3/miniconda/miniconda/envs/nlp_proj/lib/python3.8/site-packages/torch/nn/qat/__init__.py", line 1, in <module>
    from .modules import *  # noqa: F403
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 844, in exec_module
  File "<frozen importlib._bootstrap_external>", line 939, in get_code
  File "<frozen importlib._bootstrap_external>", line 1037, in get_data
KeyboardInterrupt
